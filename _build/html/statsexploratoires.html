
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Statistique exploratoire &#8212; Analyse de données</title>
    
  <!-- Loaded before other Sphinx assets -->
  <link href="_static/styles/theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">
<link href="_static/styles/pydata-sphinx-theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">

    
  <link rel="stylesheet"
    href="_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    <link rel="stylesheet" type="text/css" href="_static/pygments.css" />
    <link rel="stylesheet" href="_static/styles/sphinx-book-theme.css?digest=62ba249389abaaa9ffc34bf36a076bdc1d65ee18" type="text/css" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="_static/proof.css" />
    <link rel="stylesheet" type="text/css" href="_static/design-style.b7bb847fb20b106c3d81b95245e65545.min.css" />
    
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf">

    <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/doctools.js"></script>
    <script src="_static/togglebutton.js"></script>
    <script src="_static/clipboard.min.js"></script>
    <script src="_static/copybutton.js"></script>
    <script src="_static/scripts/sphinx-book-theme.js?digest=f31d14ad54b65d19161ba51d4ffff3a77ae00456"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="_static/sphinx-thebe.js"></script>
    <script async="async" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Régression" href="regression.html" />
    <link rel="prev" title="TP Statistiques descriptives" href="TP1_statsDescriptives.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="60">
<!-- Checkboxes to toggle the left sidebar -->
<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation" aria-label="Toggle navigation sidebar">
<label class="overlay overlay-navbar" for="__navigation">
    <div class="visually-hidden">Toggle navigation sidebar</div>
</label>
<!-- Checkboxes to toggle the in-page toc -->
<input type="checkbox" class="sidebar-toggle" name="__page-toc" id="__page-toc" aria-label="Toggle in-page Table of Contents">
<label class="overlay overlay-pagetoc" for="__page-toc">
    <div class="visually-hidden">Toggle in-page Table of Contents</div>
</label>
<!-- Headers at the top -->
<div class="announcement header-item noprint"></div>
<div class="header header-item noprint"></div>

    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<!-- Sidebar -->
<div class="bd-sidebar noprint" id="site-navigation">
    <div class="bd-sidebar__content">
        <div class="bd-sidebar__top"><div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="_static/isimainp.png" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">Analyse de données</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="intro.html">
                    Introduction
                </a>
            </li>
        </ul>
        <ul class="current nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="Rappels.html">
   Rappels
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Stats.html">
   Introduction aux statistiques
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="statsdescriptives.html">
   Statistique descriptive
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="TP1_statsDescriptives.html">
   TP Statistiques descriptives
  </a>
 </li>
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   Statistique exploratoire
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="regression.html">
   Régression
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="genindex.html">
   Index
  </a>
 </li>
</ul>

    </div>
</nav></div>
        <div class="bd-sidebar__bottom">
             <!-- To handle the deprecated key -->
            
            <div class="navbar_extra_footer">
            Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
            </div>
            
        </div>
    </div>
    <div id="rtd-footer-container"></div>
</div>


          


          
<!-- A tiny helper pixel to detect if we've scrolled -->
<div class="sbt-scroll-pixel-helper"></div>
<!-- Main content -->
<div class="col py-0 content-container">
    
    <div class="header-article row sticky-top noprint">
        



<div class="col py-1 d-flex header-article-main">
    <div class="header-article__left">
        
        <label for="__navigation"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="right"
title="Toggle navigation"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-bars"></i>
  </span>

</label>

        
    </div>
    <div class="header-article__right">
<div class="menu-dropdown menu-dropdown-launch-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Launch interactive content">
      <i class="fas fa-rocket"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="https://mybinder.org/v2/gh/executablebooks/jupyter-book/master?urlpath=tree/docs/statsexploratoires.md"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Launch on Binder"
>
  

<span class="headerbtn__icon-container">
  
    <img src="_static/images/logo_binder.svg">
  </span>
<span class="headerbtn__text-container">Binder</span>
</a>

      </li>
      
    </ul>
  </div>
</div>

<button onclick="toggleFullScreen()"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="bottom"
title="Fullscreen mode"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>

<div class="menu-dropdown menu-dropdown-repository-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Source repositories">
      <i class="fab fa-github"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="https://github.com/executablebooks/jupyter-book"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Source repository"
>
  

<span class="headerbtn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="headerbtn__text-container">repository</span>
</a>

      </li>
      
      <li>
        <a href="https://github.com/executablebooks/jupyter-book/issues/new?title=Issue%20on%20page%20%2Fstatsexploratoires.html&body=Your%20issue%20content%20here."
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Open an issue"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="headerbtn__text-container">open issue</span>
</a>

      </li>
      
    </ul>
  </div>
</div>

<div class="menu-dropdown menu-dropdown-download-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Download this page">
      <i class="fas fa-download"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="_sources/statsexploratoires.ipynb"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Download notebook file"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-code"></i>
  </span>
<span class="headerbtn__text-container">.ipynb</span>
</a>

      </li>
      
      <li>
        <a href="_sources/statsexploratoires.md"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Download source file"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="headerbtn__text-container">.md</span>
</a>

      </li>
      
      <li>
        
<button onclick="printPdf(this)"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="left"
title="Print to PDF"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="headerbtn__text-container">.pdf</span>
</button>

      </li>
      
    </ul>
  </div>
</div>
<label for="__page-toc"
  class="headerbtn headerbtn-page-toc"
  
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-list"></i>
  </span>

</label>

    </div>
</div>

<!-- Table of contents -->
<div class="col-md-3 bd-toc show noprint">
    <div class="tocsection onthispage pt-5 pb-3">
        <i class="fas fa-list"></i> Contents
    </div>
    <nav id="bd-toc-nav" aria-label="Page">
        <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#analyse-en-composantes-principales">
   Analyse en composantes principales
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#principe-de-la-methode">
     Principe de la méthode
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#pre-traitement-du-tableau">
       Pré-traitement du tableau
      </a>
      <ul class="nav section-nav flex-column">
       <li class="toc-h5 nav-item toc-entry">
        <a class="reference internal nav-link" href="#donnees-centrees">
         Données centrées
        </a>
       </li>
       <li class="toc-h5 nav-item toc-entry">
        <a class="reference internal nav-link" href="#donnees-reduites">
         Données réduites
        </a>
       </li>
      </ul>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#projection-des-individus-sur-un-sous-espace">
       Projection des individus sur un sous-espace
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#analyse-factorielle-des-correspondances">
   Analyse Factorielle des correspondances
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#analyse-des-correspondances-multiples">
   Analyse des correspondances multiples
  </a>
 </li>
</ul>

    </nav>
</div>
    </div>
    <div class="article row">
        <div class="col pl-md-3 pl-lg-5 content-container">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>Statistique exploratoire</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> Contents </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#analyse-en-composantes-principales">
   Analyse en composantes principales
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#principe-de-la-methode">
     Principe de la méthode
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#pre-traitement-du-tableau">
       Pré-traitement du tableau
      </a>
      <ul class="nav section-nav flex-column">
       <li class="toc-h5 nav-item toc-entry">
        <a class="reference internal nav-link" href="#donnees-centrees">
         Données centrées
        </a>
       </li>
       <li class="toc-h5 nav-item toc-entry">
        <a class="reference internal nav-link" href="#donnees-reduites">
         Données réduites
        </a>
       </li>
      </ul>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#projection-des-individus-sur-un-sous-espace">
       Projection des individus sur un sous-espace
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#analyse-factorielle-des-correspondances">
   Analyse Factorielle des correspondances
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#analyse-des-correspondances-multiples">
   Analyse des correspondances multiples
  </a>
 </li>
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            <main id="main-content" role="main">
                
              <div>
                
  <div class="tex2jax_ignore mathjax_ignore section" id="statistique-exploratoire">
<h1>Statistique exploratoire<a class="headerlink" href="#statistique-exploratoire" title="Permalink to this headline">#</a></h1>
<p>Les méthodes factorielles ont pour but de traiter et visualiser des données multidimensionnelles. La prise en compte simultanée de l’ensemble des variables est un problème difficile, rendu parfois plus simple car l’information apportée par les variables est redondante. Les méthodes factorielles visent alors à exploiter cette redondance pour tenter de remplacer les variables initiales par un nombre réduit de nouvelles variables, conservant au mieux l’information initiale.</p>
<p>Les principales méthodes de ce type incluent l’analyse factorielle des correspondances, l’analyse des correspondances multiples, l’analyse factorielle d’un tableau de distance (pour les tableaux de proximité) ou encore l’analyse factorielle discriminante.</p>
<div class="section" id="analyse-en-composantes-principales">
<h2>Analyse en composantes principales<a class="headerlink" href="#analyse-en-composantes-principales" title="Permalink to this headline">#</a></h2>
<p>Pour les données quantitatives, l’Analyse en Composantes Principales (ACP) est l’une des méthodes les plus utilisées. Elle considère que les nouvelles variables sont des combinaisons linéaires des variables initiales, non corrélées.</p>
<p><img alt="" src="_images/acpintro.png" /></p>
<p>Dans la suite, les données seront des tableaux <span class="math notranslate nohighlight">\(n\times p\)</span> de variables quantitatives, une ligne étant un individu, et les colonnes décrivant les paramètres mesurés. Les observations de <span class="math notranslate nohighlight">\(p\)</span> variables sur <span class="math notranslate nohighlight">\(n\)</span> individus sont donc rassemblées dans une matrice <span class="math notranslate nohighlight">\({\bf X}\in\mathcal{M}_{np}(\mathbb{R})\)</span> .  On notera <span class="math notranslate nohighlight">\(x^j\)</span> la j-ème variable, identifiée par la j-ème colonne <span class="math notranslate nohighlight">\({\bf X_{\bullet,j}}\)</span> de <span class="math notranslate nohighlight">\({\bf X}\)</span>, et <span class="math notranslate nohighlight">\(\mathbf{e_i}\)</span> le i-ème individu (i.e. <span class="math notranslate nohighlight">\({\bf X_{i,\bullet}^T}\)</span>).</p>
<div class="section" id="principe-de-la-methode">
<h3>Principe de la méthode<a class="headerlink" href="#principe-de-la-methode" title="Permalink to this headline">#</a></h3>
<div class="section" id="pre-traitement-du-tableau">
<h4>Pré-traitement du tableau<a class="headerlink" href="#pre-traitement-du-tableau" title="Permalink to this headline">#</a></h4>
<p>En analyse en composantes principales, on raisonne souvent sur des variables centrées et/ou réduites.</p>
<div class="section" id="donnees-centrees">
<h5>Données centrées<a class="headerlink" href="#donnees-centrees" title="Permalink to this headline">#</a></h5>
<p>Notons <span class="math notranslate nohighlight">\(\mathbf{g} = \left ( \bar{x}^1\cdots \bar{x}^p\right )\)</span> le vecteur des moyennes arithmétiques de chaque variable (centre de gravité) :</p>
<p><span class="math notranslate nohighlight">\(\mathbf{g}={\bf X^TD\mathbf{1}}\)</span></p>
<p>où <span class="math notranslate nohighlight">\({\bf D}\)</span> est une matrice diagonale de poids,  chaque <span class="math notranslate nohighlight">\(d_{ii}\)</span> donnant l’importance de l’individu <span class="math notranslate nohighlight">\(i\)</span> dans les données (le plus souvent <span class="math notranslate nohighlight">\({\bf D}=\frac{1}{n}{ \mathbb{I}}\)</span>),  et <span class="math notranslate nohighlight">\(\mathbf{1}\)</span> est le vecteur de <span class="math notranslate nohighlight">\(\mathbb{R}^n\)</span> dont toutes les composantes sont égales à 1. Le tableau <span class="math notranslate nohighlight">\({\bf Y}={\bf X}-\mathbf{1}\mathbf{g}^T=({ \mathbb{I}}-\mathbf{1}\mathbf{1}^T{\bf D}){\bf X}\)</span> est le tableau centré associé à <span class="math notranslate nohighlight">\({\bf X}\)</span>.</p>
</div>
<div class="section" id="donnees-reduites">
<h5>Données réduites<a class="headerlink" href="#donnees-reduites" title="Permalink to this headline">#</a></h5>
<p>La matrice de variance/covariance des données centrées est égale à
<span class="math notranslate nohighlight">\({\bf V} = {\bf X^TDX} - \mathbf{g}\mathbf{g^T} = {\bf Y^TDY}\)</span>.</p>
<p>Si on note <span class="math notranslate nohighlight">\({\bf D_{1/\sigma}}\)</span> la matrice diagonale des inverses des écarts-types des variables, alors  <span class="math notranslate nohighlight">\({\bf Z}={\bf YD_{1/\sigma}}\)</span>
est la matrice des données centrées réduites. La matrice <span class="math notranslate nohighlight">\({\bf R}={\bf D_{1/\sigma}VD_{1/\sigma}}={\bf Z^TDZ}\)</span>
est la matrice de corrélation des données et résume la structure des dépendances linéaires entre les <span class="math notranslate nohighlight">\(p\)</span> variables.</p>
</div>
</div>
<div class="section" id="projection-des-individus-sur-un-sous-espace">
<h4>Projection des individus sur un sous-espace<a class="headerlink" href="#projection-des-individus-sur-un-sous-espace" title="Permalink to this headline">#</a></h4>
<p>Le principe de la méthode est d’obtenir une représentation approchée du nuage des <span class="math notranslate nohighlight">\(n\)</span> individus dans un sous-espace <span class="math notranslate nohighlight">\(F_k\)</span> de dimension faible. Ceci s’effectue par un mécanisme de projection.</p>
<p>Le choix de l’espace de projection est dicté par le critère suivant, qui revient à déformer le moins possible les distances en projection: le sous-espace de dimension <span class="math notranslate nohighlight">\(k\)</span> recherché est tel que la moyenne des carrés des distances entre projections soit la plus grande possible. En définissant l’inertie d’un nuage de points comme la moyenne pondérée des carrés des distances au centre de gravité, le critère revient alors à maximiser l’inertie du nuage projeté sur <span class="math notranslate nohighlight">\(F_k\)</span>.</p>
<p>Soit <span class="math notranslate nohighlight">\({\bf P}\)</span> la projection orthogonale sur <span class="math notranslate nohighlight">\(F_k\)</span>. Le nuage de points projeté est associé au tableau <span class="math notranslate nohighlight">\({\bf XP^T}\)</span> puisque chaque individu <span class="math notranslate nohighlight">\(\mathbf{e_i}\)</span> se projette sur <span class="math notranslate nohighlight">\(F_k\)</span> selon un vecteur colonne <span class="math notranslate nohighlight">\(\mathbf{Pe_i}\)</span> ou un vecteur ligne <span class="math notranslate nohighlight">\(\mathbf{e_iP^T}\)</span>.</p>
<p>La matrice de variance du tableau <span class="math notranslate nohighlight">\({\bf XP^T}\)</span> est, dans le cas où les variables sont centrées :
<span class="math notranslate nohighlight">\({\bf (XP^T)^TD(XP^T) }= {\bf PVP^T}\)</span>
L’inertie du nuage projeté est donc égale à <span class="math notranslate nohighlight">\(Tr({\bf PVP^TM})\)</span>, où <span class="math notranslate nohighlight">\({\bf M}\)</span> est une matrice symétrique définie positive de taille <span class="math notranslate nohighlight">\(p\)</span>, définissant la distance entre deux individus</p>
<p><span class="math notranslate nohighlight">\(d^2(\mathbf{e_i},\mathbf{e_j}) = (\mathbf{e_i}-\mathbf{e_j})^T{\bf M}(\mathbf{e_i}-\mathbf{e_j})\)</span></p>
<p>Mais
<span class="math notranslate nohighlight">\(\begin{eqnarray*}
Tr({\bf PVP^TM})&amp;=&amp;Tr({\bf PVMP})\quad \textrm{car }{\bf P^TM}={\bf MP}\\
&amp;=&amp; Tr({\bf VMP^2})\quad \textrm{car }Tr({\bf AB})=Tr({\bf BA})\\
&amp;=&amp;Tr({\bf VMP})\quad \textrm{car } P\textrm{ est une projection}
\end{eqnarray*}\)</span></p>
<p>Le problème posé est donc de trouver la projection <span class="math notranslate nohighlight">\({\bf P}\)</span>, de rang <span class="math notranslate nohighlight">\(k\)</span> maximisant <span class="math notranslate nohighlight">\(Tr({\bf VMP})\)</span>. La projection <span class="math notranslate nohighlight">\({\bf P}\)</span> réalisant cette optimisation donnera alors <span class="math notranslate nohighlight">\(F_k\)</span>.</p>
<p>L’analyse en composantes principales consiste alors, de manière itérative, à chercher un sous-espace de dimension 1 d’inertie maximale, puis le sous-espace de dimension 1 orthogonal au précédent d’inertie maximale et ainsi de suite. Elle s’appuie sur le résultat suivant :
\begin{theo}{}{}
Soit <span class="math notranslate nohighlight">\(F_k\)</span> un sous-espace portant l’inertie maximale. Alors le sous-espace de dimension <span class="math notranslate nohighlight">\(k+1\)</span> portant l’inertie maximale est la somme directe de <span class="math notranslate nohighlight">\(F_k\)</span> et de la droite orthogonale à <span class="math notranslate nohighlight">\(F_k\)</span> portant l’inertie maximale.
\end{theo}</p>
<p>\subsection{Elements principaux}
\subsubsection*{Axes principaux}
Rechercher un sous-espace de dimension 1 d’inertie maximale revient à rechercher une droite de <span class="math notranslate nohighlight">\(\mathbb{R}^n\)</span> passant par le centre de gravité des données <span class="math notranslate nohighlight">\(\mathbf{g}\)</span> maximisant l’inertie du nuage projeté sur cet axe. Soit <span class="math notranslate nohighlight">\(\mathbf{a}\)</span> un vecteur directeur de cette droite. La projection orthogonale sur la droite est définie par la matrice de projection
$<span class="math notranslate nohighlight">\(\mathbf P=\frac{\mathbf{a}\mathbf{a}^T{\bf M}}{\mathbf{a}^T{\bf M}\mathbf{a}}\)</span>$</p>
<p>L’inertie du nuage projeté sur <span class="math notranslate nohighlight">\(Lin(\mathbf{a})\)</span> vaut alors
\begin{eqnarray*}
Tr({\bf VMP})&amp;=&amp;Tr\left ({\bf VM}\frac{\mathbf{a}\mathbf{a}^T{\bf M}}{\mathbf{a}^T{\bf M}\mathbf{a}}\right )\
&amp;=&amp; \frac{1}{\mathbf{a^T}{\bf M}\mathbf{a}}Tr({\bf VM}\mathbf{a}\mathbf{a^T}{\bf M})\
&amp;=&amp; \frac{1}{\mathbf{a^T}{\bf M}\mathbf{a}}Tr(\mathbf{a^T}{\bf MVM}\mathbf{a})\quad \text{car } Tr(\mathbf{AB})=Tr(\mathbf{BA})\
&amp;=&amp; \frac{1}{\mathbf{a^T}{\bf M}\mathbf{a}}\mathbf{a^T}{\bf MVM}\mathbf{a}\quad \text{car } \mathbf{a^T}{\bf MVM}\mathbf{a}\in\mathbb{R}
\end{eqnarray*}</p>
<p>La matrice <span class="math notranslate nohighlight">\({\bf MVM}\)</span> est la matrice d’inertie du nuage (égale à la matrice de variance-covariance si <span class="math notranslate nohighlight">\({\bf M}=\mathbb I\)</span>).  Maximiser cette quantité revient à annuler sa dérivée par rapport à <span class="math notranslate nohighlight">\(\mathbf{a}\)</span> d’où :
$<span class="math notranslate nohighlight">\(
\frac{d}{d\mathbf{a}}\frac{\mathbf{a^T}{\bf MVM}\mathbf{a}}{\mathbf{a^T}{\bf M}\mathbf{a}}=\frac{(\mathbf{a^T}{\bf M}\mathbf{a})2{\bf MVM}\mathbf{a}-(\mathbf{a^T}{\bf MVM}\mathbf{a})2{\bf M}\mathbf{a}}{(\mathbf{a^T}{\bf M}\mathbf{a})^2}
\)</span><span class="math notranslate nohighlight">\(
et donc 
\)</span><span class="math notranslate nohighlight">\({\bf MVM}\mathbf{a}=\left (\frac{\mathbf{a^T}{\bf MVM}\mathbf{a}}{\mathbf{a^T}{\bf M}\mathbf{a}} \right ){\bf M}\mathbf{a}\)</span><span class="math notranslate nohighlight">\(
soit \)</span>{\bf VM}\mathbf{a}=\lambda \mathbf{a}<span class="math notranslate nohighlight">\( car \)</span>{\bf M}<span class="math notranslate nohighlight">\( est de rang plein. Donc \)</span>\mathbf{a}<span class="math notranslate nohighlight">\( est vecteur propre de \)</span>{\bf VM}<span class="math notranslate nohighlight">\(, et \)</span>\lambda<span class="math notranslate nohighlight">\( est la plus grande des valeurs propres de \)</span>{\bf VM}<span class="math notranslate nohighlight">\(. Or \)</span>{\bf M}<span class="math notranslate nohighlight">\( est symétrique, elle est diagonalisable sur une base de vecteurs propres orthonormés et on a le résultat suivant :
\begin{theo}{}{}
Le sous-espace \)</span>F_k<span class="math notranslate nohighlight">\( de dimension \)</span>k<span class="math notranslate nohighlight">\( portant l'inertie maximale est engendré par les \)</span>k<span class="math notranslate nohighlight">\( premiers vecteurs propres de \)</span>{\bf VM}<span class="math notranslate nohighlight">\(
\end{theo}
Les droites portées par ces vecteurs propres sont les axes principaux. Dans la suite on supposera \)</span>\mathbf{a}<span class="math notranslate nohighlight">\( \)</span>\mathbf M$-normé.</p>
<p>\subsubsection*{Facteurs principaux}
On associe à  <span class="math notranslate nohighlight">\(Lin(\mathbf{a})\)</span> la forme linéaire <span class="math notranslate nohighlight">\(\mathbf{u}\)</span>, coordonnée orthogonale sur l’axe <span class="math notranslate nohighlight">\(Lin(\mathbf{a})\)</span>. Le vecteur <span class="math notranslate nohighlight">\(\mathbf{u}\)</span> définit une combinaison linéaire des variables descriptives <span class="math notranslate nohighlight">\(x^1\cdots x^p\)</span>. A l’axe principal <span class="math notranslate nohighlight">\(\mathbf{a}\)</span> est associé le facteur principal <span class="math notranslate nohighlight">\(\mathbf{u}=\mathbf{Ma}\)</span>. Puisque <span class="math notranslate nohighlight">\(\mathbf{a}\)</span> est vecteur propre de <span class="math notranslate nohighlight">\({\bf VM}\)</span>, on peut alors écrire
$<span class="math notranslate nohighlight">\({\bf MVM}\mathbf{a}=\lambda {\bf M}\mathbf{a}\)</span><span class="math notranslate nohighlight">\( 
et donc \)</span>{\bf MV}\mathbf{u}=\lambda \mathbf{u}<span class="math notranslate nohighlight">\(.  Les facteurs principaux sont donc les vecteurs propres de \)</span>{\bf MV}$</p>
<p>\subsubsection*{Composantes principales}
Les composantes principales sont les éléments de <span class="math notranslate nohighlight">\(\mathbb{R}^n\)</span> définis par <span class="math notranslate nohighlight">\(\mathbf{c_i}=\mathbf{Xu_i}\)</span>. Ce sont donc les vecteurs coordonnées des projections orthogonales des individus sur les axes propres <span class="math notranslate nohighlight">\(\mathbf{a_i}\)</span>.  Ce sont donc les combinaisons linéaires des <span class="math notranslate nohighlight">\(x^1\cdots x^p\)</span> de variance maximale sous la contrainte <span class="math notranslate nohighlight">\(\mathbf{u_i}^T{\bf M}\mathbf{u_i}=1\)</span>, et cette variance est égale à la valeur propre <span class="math notranslate nohighlight">\(\lambda_i\)</span> associée à <span class="math notranslate nohighlight">\(\mathbf{a_i}\)</span>.
\vskip 6pt
En pratique, l’analyse en composantes principales consiste à calculer les <span class="math notranslate nohighlight">\(\mathbf{u}\)</span> par diagonalisation de <span class="math notranslate nohighlight">\({\bf MV}\)</span>, puis à calculer les <span class="math notranslate nohighlight">\(\mathbf{c}=\mathbf{Xu}\)</span>. Le calcul explicite des vecteurs propres <span class="math notranslate nohighlight">\(\mathbf{a}\)</span> n’a que peu d’intérêt.</p>
<p>\subsubsection*{Reconstitution}
Il est possible de reconstituer le tableau <span class="math notranslate nohighlight">\({\bf X}\)</span> centré des données (ou une approximation par une matrice de rang <span class="math notranslate nohighlight">\(k\)</span>) en utilisant les composantes. En effet, puisque <span class="math notranslate nohighlight">\(\mathbf{Xu_j}=\mathbf{c_j}\)</span> on a
$<span class="math notranslate nohighlight">\({\bf X}\displaystyle\sum_j \mathbf{u_j}\mathbf{u_j}^T{\bf M^{-1}} = \displaystyle\sum_j\mathbf{c_j}\mathbf{u_j}^T{\bf M^{-1}}\)</span><span class="math notranslate nohighlight">\(
Mais \)</span>\displaystyle\sum_j \mathbf{u_j}\mathbf{u_j}^T{\bf M^{-1}}=\mathbb{I}<span class="math notranslate nohighlight">\(  car les \)</span>\mathbf{u_j}<span class="math notranslate nohighlight">\( sont orthonormés pour la métrique \)</span>{\bf M^{-1}}<span class="math notranslate nohighlight">\( donc 
\)</span><span class="math notranslate nohighlight">\({\bf X}=\displaystyle\sum_j\mathbf{c_j}\mathbf{u_j}^T{\bf M^{-1}}\)</span><span class="math notranslate nohighlight">\(
et si l'on s'intéresse à l'approximation de \)</span>{\bf X}<span class="math notranslate nohighlight">\( on ne somme que les \)</span>k$ premiers termes.</p>
<p>A noter que lorsque <span class="math notranslate nohighlight">\({\bf M}=\mathbb{I}, {\bf X}= \displaystyle\sum_j\sqrt{\lambda_j}\mathbf{z_j}\mathbf{v_j^T}\)</span> où les <span class="math notranslate nohighlight">\(\mathbf{z_j}\)</span> sont les vecteurs propres unitaires de <span class="math notranslate nohighlight">\({\bf XX^T}\)</span> et les <span class="math notranslate nohighlight">\(\mathbf{v_j}\)</span> les vecteurs propres unitaires de <span class="math notranslate nohighlight">\({\bf X^TX}\)</span> (décomposition en valeurs singulières).</p>
<p>\section{Interprétation des résultats}
\subsection{Quelle dimension pour <span class="math notranslate nohighlight">\(F_k\)</span> ?}
Le but premier de l’ACP est de réduire la dimension pour permettre une visualisation efficace des données, tout en préservant l’information (ici représentée par la variance du nuage de points).  Il faut donc se doter d’outils permettant de répondre à la question : quelle dimension pour <span class="math notranslate nohighlight">\(F_k\)</span> ? Il n’y a pas de réponse théorique satisfaisante, l’essentiel étant d’avoir une représentation suffisamment expressive pour permettre une interprétation correcte du nuage de points.
En préambule, il convient de remarquer que la réduction de dimension ne sera possible que si les variables <span class="math notranslate nohighlight">\(x^1\cdots x^p\)</span> ne sont pas indépendantes.</p>
<p>\subsubsection*{Critère théorique}
On détermine ici si les valeurs propres sont significativement différentes entre elles à partir d’un certain rang: si la réponse est négative on conserve les
premières valeurs propres.</p>
<p>On fait l’hypothèse que les <span class="math notranslate nohighlight">\(n\)</span> individus proviennent d’un tirage aléatoire dans une population gaussienne  où <span class="math notranslate nohighlight">\(\lambda_{k+1}=\cdots =\lambda_{p}\)</span>. Si l’hypothèse est vérifiée, la moyenne arithmétique <span class="math notranslate nohighlight">\(\alpha\)</span> des <span class="math notranslate nohighlight">\(p-k\)</span> dernières valeurs propres et leur moyenne géométrique <span class="math notranslate nohighlight">\(\gamma\)</span> sont peu différentes. On admet que :
$<span class="math notranslate nohighlight">\(c=\left ( n-\frac{2p+11}{6}\right )(p-k) ln\frac{\alpha}{\gamma}\)</span><span class="math notranslate nohighlight">\(
suit une loi du \)</span>\chi^2<span class="math notranslate nohighlight">\( de degré de liberté \)</span>\frac{(p-k+2)(p-k-1)}{2}<span class="math notranslate nohighlight">\( et on rejette l'hypothèse d'égalité des \)</span>p-k<span class="math notranslate nohighlight">\( valeurs propres si \)</span>c$ est trop grand.</p>
<p>\subsubsection*{Pourcentage d’inertie}
Le critère couramment utilisé est le pourcentage d’inertie totale expliquée (figure \ref{F:inertie}), qui s’exprime sur les <span class="math notranslate nohighlight">\(k\)</span> premiers axes par :
$<span class="math notranslate nohighlight">\(\frac{\displaystyle\sum_{j=1}^k \lambda_j}{\displaystyle\sum_{j=1}^p \lambda_j}\)</span><span class="math notranslate nohighlight">\(
Un seuil par exemple de 90\% d'inertie totale expliquée donne une valeur de \)</span>k$ correspondante. Attention cependant, le pourcentage d’inertie doit faire intervenir le nombre de variables initiales.</p>
<p>\begin{center}
\begin{figure}[hbtp]
\centering
\includegraphics[width=\columnwidth]{figures/scree}
\caption{Pourcentage d’inertie (ou variance) expliquée par les composantes principales}
\label{F:inertie}
\end{figure}
\end{center}</p>
<p>\subsubsection*{Mesures locales}
Le pourcentage d’inertie expliquée est un critère global qui doit être complété par d’autres considérations. Supposons que le plan <span class="math notranslate nohighlight">\(F_2\)</span> explique une part importante d’inertie, et que, en projection sur ce plan, deux individus soient très proches (figure \ref{F:projImA}). Cette proximité peut être illusoire si les deux individus se trouvent éloignés dans l’orthogonal de <span class="math notranslate nohighlight">\(F_2\)</span>. Pour prendre en compte ce phénomène, il faut envisager pour chaque individu <span class="math notranslate nohighlight">\(\mathbf{e_i}\)</span> la qualité de sa représentation, souvent exprimée par le cosinus de l’angle entre le plan principal et le vecteur <span class="math notranslate nohighlight">\(\mathbf{e_i}\)</span>. Si ce cosinus est grand, <span class="math notranslate nohighlight">\(\mathbf{e_i}\)</span> est voisin du plan, on peut  alors examiner la position de sa projection sur le plan par rapport à d’autres points.</p>
<p>\begin{figure}[hbtp!]
\begin{center}
\begin{tikzpicture}[line cap=round,line join=round,&gt;=triangle 45,x=1.0cm,y=1.0cm,scale=0.5]
\clip(-3.52,-5.76) rectangle (7.36,5.76);
\filldraw[fill=blue!20!] (-3.5,-2) – (3.5,-2) –  (5.5,1) – (-0.5,1) – (-3.5,-2);
\draw<span class="xref myst">-</span> – (0,4);</p>
<p>\draw [-&gt;,line width=1.6pt,blue] (0.,0.) – (3.84,3.62);
\draw [-&gt;,line width=1.6pt,blue] (0.,0.) – (3.84,-3.62);
\draw [-&gt;,line width=1.2pt,cyan] (0.,0.) – (3.84,-1.64);
\draw [-&gt;,line width=1.6pt,red] (0.,0.) – (0,3.62);
\draw [dash pattern=on 4pt off 4pt] (3.84,3.62)– (3.84,-1.64);
\draw [dash pattern=on 4pt off 4pt] (3.84,-3.62)– (3.84,-1.64);
\draw (-0.54,4.74) node[anchor=north west] { <span class="math notranslate nohighlight">\(F_2^\perp\)</span> };</p>
<p>\draw (3.84,3.62) node[anchor=north west] { <span class="math notranslate nohighlight">\(\textcolor{blue}{{\bf e_i}}\)</span> };
\draw (3.84,-3.62) node[anchor=north west] { <span class="math notranslate nohighlight">\(\textcolor{blue}{{\bf e_j}}\)</span> };
\draw (3.84,-1.64) node[anchor=north west] { <span class="math notranslate nohighlight">\(\textcolor{cyan}{{\bf p}}\)</span> };
\draw (1.54,3.62) node[anchor=north west] { <span class="math notranslate nohighlight">\(\textcolor{red}{{\bf u}}\)</span> };
\draw (-3.5,-2) node[anchor=north west] { <span class="math notranslate nohighlight">\(F_2\)</span> };
\end{tikzpicture}</p>
<p>\end{center}
\caption{<span class="math notranslate nohighlight">\({\bf e_i} \)</span> et <span class="math notranslate nohighlight">\({\bf e_j}\)</span> se projettent sur <span class="math notranslate nohighlight">\(F_2\)</span> en <span class="math notranslate nohighlight">\({\bf p}\)</span> mais sont éloignés dans <span class="math notranslate nohighlight">\(F_2^\perp\)</span>}<br />
\label{F:projImA}
\end{figure}</p>
<p>\subsubsection*{Critères empiriques}</p>
<p>Lorsqu’on travaille sur données centrées réduites, on retient les composantes principales correspondant à des valeurs propres supérieures à 1 (critère de Kaiser) : en effet les composantes principales <span class="math notranslate nohighlight">\(c_j\)</span> étant des combinaisons linéaires des <span class="math notranslate nohighlight">\(z-j\)</span> de variance maximale <span class="math notranslate nohighlight">\(V(c_j)=\lambda\)</span>, seules les composantes de variance supérieure à celle des variables initiales présentent un intérêt.</p>
<p>\subsection{Interprétation des résultats : exemple}</p>
<p>Une analyse en composantes principales est réalisée sur un jeu de données composé de 9 indicateurs de qualité pour 329 villes américaines. Les paragraphes suivants sont illustrés par ces données.</p>
<p>\subsubsection*{Corrélation variables-facteurs}
Pour donner du sens aux composantes principales <span class="math notranslate nohighlight">\(\mathbf{c}\)</span>, il faut les relier aux variables initiales <span class="math notranslate nohighlight">\(x^j\)</span> en calculant les coefficients de corrélation linéaire  <span class="math notranslate nohighlight">\(r(\mathbf{c},x^j)\)</span> et en seuillant ces coefficients en valeur absolue.</p>
<p>Lorsque l’on travaille sur des données centrées réduites (métrique <span class="math notranslate nohighlight">\(\mathbf D_{1/\sigma}\)</span>), le calcul de <span class="math notranslate nohighlight">\(r(\mathbf{c},x^j)\)</span> se réduit à
$<span class="math notranslate nohighlight">\(r(\mathbf{c},x^j)=\frac{\mathbf{c}^T\mathbf D\mathbf{z^j}}{\sqrt{\lambda}}\)</span><span class="math notranslate nohighlight">\(
Or \)</span>\mathbf{c}=Z\mathbf{u}<span class="math notranslate nohighlight">\( où \)</span>\mathbf{u}<span class="math notranslate nohighlight">\(, facteur principal associé à \)</span>\mathbf{c}<span class="math notranslate nohighlight">\(, est vecteur propre de la matrice de corrélation \)</span>\mathbf R<span class="math notranslate nohighlight">\( associé à \)</span>\lambda<span class="math notranslate nohighlight">\(. Donc
\)</span><span class="math notranslate nohighlight">\(r(\mathbf{c},x^j)=\frac{\mathbf{u}^T\mathbf Z^T\mathbf D\mathbf{z^j}}{\sqrt{\lambda}}=\frac{(\mathbf{z^j})^T\mathbf D\mathbf Z\mathbf{u}}{\sqrt{\lambda}}\)</span><span class="math notranslate nohighlight">\(
\)</span>(\mathbf{z^j})^T\mathbf D\mathbf Z<span class="math notranslate nohighlight">\( est la \)</span>j^e<span class="math notranslate nohighlight">\( ligne de \)</span>\mathbf Z^T\mathbf D\mathbf Z=\mathbf R<span class="math notranslate nohighlight">\( donc \)</span>(\mathbf{z^j})^T\mathbf D \mathbf Z \mathbf{u}<span class="math notranslate nohighlight">\( est la \)</span>j^e<span class="math notranslate nohighlight">\( composante de \)</span>\mathbf R\mathbf{u}=\lambda \mathbf{u}<span class="math notranslate nohighlight">\( d'où
\)</span><span class="math notranslate nohighlight">\(r(\mathbf{c},x^j)=\sqrt{\lambda}u_j\)</span>$</p>
<p>Ces calculs s’effectuent pour chaque composante principale. Pour un couple de composantes principales <span class="math notranslate nohighlight">\(\mathbf{c_1}\)</span> et <span class="math notranslate nohighlight">\(\mathbf{c_2}\)</span> par exemple on représente fréquemment les corrélations sur une figure appelée « cercle des corrélations» (figure \ref{F:cercle}) où chaque variable <span class="math notranslate nohighlight">\(x^j\)</span> est repérée par un point d’abscisse <span class="math notranslate nohighlight">\(r(\mathbf{c_1},x^j)\)</span> et d’ordonnée <span class="math notranslate nohighlight">\(r(\mathbf{c_2},x^j)\)</span>.</p>
<p>\begin{center}
\begin{figure}[hbtp!]
\centering
\includegraphics[width=.7\textwidth]{figures/cercle}
\caption{Cercle des corrélations : exemple sur des variables de qualité de vie mesurés dans des villes américaines.}
\label{F:cercle}
\end{figure}
\end{center}</p>
<p>\begin{rem}
Attention de ne pas interpréter des proximités entre points variables, si ceux-ci ne sont pas proches de la circonférence.
\end{rem}</p>
<p>Notons que dans le cas de la métrique <span class="math notranslate nohighlight">\(D_{1/\sigma}\)</span>, le cercle des corrélations est la projection de l’ensemble des variables centrées-réduites sur le sous-espace engendré par <span class="math notranslate nohighlight">\(\mathbf{c_1},\mathbf{c_2}\)</span>. En ce sens, le cercle de corrélation est le pendant, dans l’espace des variables, de la projection des individus sur le premier plan principal.</p>
<p>\subsection{Positionnement des individus}
Dire que <span class="math notranslate nohighlight">\(\mathbf{c_1}\)</span> est très corrélée à <span class="math notranslate nohighlight">\(x^j\)</span> signifie que les individus ayant une forte coordonnée positive sur l’axe 1 sont caractérisés par une valeur de <span class="math notranslate nohighlight">\(x^j\)</span> nettement supérieure à la moyenne.</p>
<p>Il est très utile aussi de calculer pour chaque axe la contribution apportée par les divers individus à cet axe. Si <span class="math notranslate nohighlight">\(c_{ki}\)</span> est la valeur de la composante <span class="math notranslate nohighlight">\(k\)</span> pour le <span class="math notranslate nohighlight">\(i^e\)</span> individu, alors par construction
$<span class="math notranslate nohighlight">\(\displaystyle\sum_{i=1}^np_ic_{ki}^2=\lambda_k\)</span><span class="math notranslate nohighlight">\(
où \)</span>p_i<span class="math notranslate nohighlight">\( est le poids de l'individu \)</span>i<span class="math notranslate nohighlight">\(. On appelle alors contribution de l'individu \)</span>i<span class="math notranslate nohighlight">\( à la composante \)</span>\mathbf{c_k}<span class="math notranslate nohighlight">\( la quantité \)</span>\frac{p_ic_{ki}^2}{\lambda_k}<span class="math notranslate nohighlight">\(. Dans le cas où le poids est différent de \)</span>1/n$ (certains individus sont “plus importants” que d’autres), la contribution est riche d’interprétation. Dans le cas contraire, elle n’apporte rien de plus que les coordonnées de l’individu.</p>
<p>On peut alors positionner les individus sur les sous-espaces des premières composantes principales (plans factoriels). La figure \ref{F:plan2} présente le positionnement de 329 villes américaines, où les 9 variables de qualité de vie précédentes ont été mesurées. Par soucis de lisibilité, seul les villes qui contribuent le plus à la création de la première composante principale ont leurs noms inscrits.</p>
<p>\begin{center}
\begin{figure}[hbtp!]
\centering
\includegraphics[width=\columnwidth]{figures/individus}
\caption{Projection des individus  (villes) sur le plan des deux premières composantes principales}
\label{F:plan2}
\end{figure}
\end{center}</p>
<p>On peut également superposer les deux informations précédentes pour corréler le positionnement des villes selon les variables originales. La figure \ref{F:biplot} présente les 329 villes précédentes, plongées dans <span class="math notranslate nohighlight">\(F_3\)</span>, les  anciennes variables étant matérialisées par des vecteurs dont la direction et la norme indiquent à quel point chaque variable contribue aux 3 premières composantes principales.</p>
<p>\begin{center}
\begin{figure}[hbtp!]
\centering
\includegraphics[width=\columnwidth]{figures/biplot}
\caption{Représentation des individus et des variables originales dans l’espace des trois premières composantes principales}
\label{F:biplot}
\end{figure}
\end{center}</p>
<p>Il n’est pas souhaitable, et ceci surtout pour les premières composantes,  qu’un individu ait une contribution excessive car cela serait un facteur d’instabilité, le fait de retirer cet individu modifiant profondément le résultat de l’analyse. Si ce cas se produisait il y aurait intérêt à effectuer l’analyse en éliminant cet individu puis en le mettant en élément supplémentaire, s’il ne s’agit pas d’une donnée erronée qui a été ainsi mise en évidence.</p>
<p>\subsection*{Facteur de taille, facteur de forme}
Le théorème de Frobenius stipule qu’une matrice symétrique n’ayant que des termes positifs admet un premier vecteur propre dont toutes les composantes sont de même signe. Si ce signe est positif, la première composante est alors corrélée positivement avec toutes les variables et les individus sont rangés sur l’axe 1 par valeurs croissantes de l’ensemble des variables. Si de plus les corrélations entre variables sont du même ordre de grandeur, la première composante principale est proportionnelle à la moyenne des variables initiales. Cette première composante définit alors un facteur de taille.</p>
<p>La deuxième composante principale différencie alors des individus de “taille” semblable, on l’appelle souvent facteur de forme.</p>
<p>\subsection{Ajout de variable et ou d’individu}
Toutes les interprétations précédentes expliquent les résultats à l’aide des données initiales, qui ont permis de les calculer. On risque alors de prendre pour une propriété intrinsèque des données un simple artefact de la méthode (par exemple il existe de fortes corrélations entre la première composante principale et certaines variables, puisque <span class="math notranslate nohighlight">\(\mathbf{c_1}\)</span> maximise <span class="math notranslate nohighlight">\(\sum_j r^2(\mathbf{c},x^j)\)</span>).</p>
<p>En revanche une forte corrélation entre une composante principale et une variable qui n’a pas servi à l’analyse sera significative. D’où la pratique courante de partager en deux groupes l’ensemble des variables: d’une part les variables actives qui servent à déterminer les axes principaux, d’autre part les variables passives ou supplémentaires que l’on relie a posteriori aux composantes principales. On distingue alors les variables supplémentaires suivant leur type, numérique (à placer dans les cercles de corrélation) ou qualitative (donnée d’une partition des <span class="math notranslate nohighlight">\(n\)</span> individus en <span class="math notranslate nohighlight">\(k\)</span> classes).</p>
<p>\section{Exemple}
On étudie les consommations annuelles en 1972, exprimées en devises, de 8 denrées alimentaires (les variables), les individus étant 8 catégories socio-professionnelles (CSP) . Les données sont des moyennes par CSP :</p>
<p>\begin{center}
\begin{tabular}{|c|cccccccc|}
\hline
&amp;PAO  &amp;PAA  &amp;VIO&amp; VIA&amp;  POT&amp;  LEC &amp;RAI&amp; PLP\
\hline
AGRI  &amp;167  &amp;1  &amp;163&amp; 23&amp; 41  &amp;8&amp; 6 &amp;6\
SAAG  &amp;162&amp; 2 &amp;141&amp; 12  &amp;40 &amp;12&amp;  4&amp;  15\
PRIN  &amp;119&amp; 6 &amp;69 &amp;56 &amp;39&amp;  5 &amp;13 &amp;41\
CSUP  &amp;87 &amp;11 &amp;63 &amp;111&amp; 27&amp; 3 &amp;18 &amp;39\
CMOY  &amp;103  &amp;5  &amp;68 &amp;77 &amp;32&amp;  4 &amp;11 &amp;30\
EMPL  &amp;111  &amp;4  &amp;72 &amp;66 &amp;34&amp;  6 &amp;10 &amp;28\
OUVR  &amp;130  &amp;3  &amp;76 &amp;52 &amp;43&amp;  7 &amp;7  &amp;16\
INAC  &amp;138  &amp;7  &amp;117  &amp;74&amp;  53&amp; 8 &amp;12 &amp;20\
\hline
\end{tabular}
\end{center}</p>
<p>avec les notations suivantes :</p>
<p>\begin{tiny}
AGRI = Exploitants agricoles, SAAG= Salariés agricoles,   PRIN = Professions indépendantes, CSUP = Cadres supérieurs, CMOY= Cadres moyens, EMPL= Employés, OUVR = Ouvriers, INAC = Inactifs.
\end{tiny}</p>
<p>et</p>
<p>\begin{tiny}
PAO = Pain ordinaire, PAA = Autre pain, VIO = Vin ordinaire, VIA=Autre vin, POT= Pommes de terre, LEC=Légumes secs, RAI=Raisin de table, PLP= Plats préparés.
\end{tiny}</p>
<p>La matrice de corrélation des variables est alors</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{pmatrix}
   1.0000   &amp;  -.7737    &amp; 0.9262    &amp; -.9058    &amp; 0.6564  &amp;   0.8886   &amp;  -.8334  &amp;   -.8558\\
    -.7737    &amp; 1.0000    &amp; -.6040    &amp; 0.9044    &amp; -.3329    &amp; -.6734    &amp; 0.9588    &amp; 0.7712\\
   0.9262    &amp; -.6040    &amp; 1.0000    &amp; -.7502    &amp; 0.5171    &amp; 0.7917   &amp;  -.6690     &amp;-.8280\\
  -.9058    &amp; 0.9044    &amp; -.7502    &amp; 1.0000    &amp; -.4186    &amp; -.8386    &amp; 0.9239     &amp;0.7198\\
    0.6564   &amp;  -.3329    &amp; 0.5171    &amp; -.4186    &amp; 1.0000   &amp;  0.6029   &amp;  -.4099    &amp; -.5540\\
  0.8886   &amp;  -.6734    &amp; 0.7917   &amp;  -.8386    &amp; 0.6029   &amp;  1.0000   &amp;  -.8245    &amp; -.7509\\
  -.8334    &amp; 0.9588    &amp; -.6690    &amp; 0.9239    &amp; -.4099    &amp; -.8245    &amp; 1.0000     &amp;0.8344\\
   -.8558    &amp; 0.7712   &amp;  -.8280   &amp;  0.7198   &amp;  -.5540    &amp; -.7509  &amp;   0.8344    &amp; 1.0000\\
\end{pmatrix}\end{split}\]</div>
<p>et son analyse spectrale donne</p>
<p>\begin{tabular}{|c||c|c|c|}
\hline
&amp;    Valeur propre  &amp;      Variance expliquée  &amp;  Variance cumulative expliquée\
\hline
1  &amp;  6.20794684      &amp;      0.7760  &amp;      0.7760\
2   &amp; 0.87968139      &amp;      0.1100    &amp;    0.8860\
3    &amp;0.41596112    &amp;        0.0520      &amp;  0.9379\
4    &amp;0.30645467    &amp;        0.0383      &amp;  0.9763\
5    &amp;0.16844150    &amp;        0.0211      &amp;  0.9973\
6    &amp;0.01806771    &amp;       0.0023       &amp; 0.9996\
7    &amp;0.00344677    &amp;       0.0004       &amp; 1.0000\
8    &amp;0.00000000        &amp;              0.0000      &amp;  1.0000\
\hline
\end{tabular}</p>
<p>Le critère de Kaiser  conduit à sélectionner un seul axe, qui retient 77% de l’inertie totale. L’axe 2 retenant 11% de l’inertie, il peut être  intéressant de le rajouter à l’étude pour expliquer près de 90% de la variance des données. Les figures \ref{Fig:var} et \ref{Fig:ind} représentent les variables et les individus dans le plan des deux premiers vecteurs propres.</p>
<p>\begin{figure}[hbtp!]
\begin{center}
\hspace*{\stretch{1}}
\subfigure[Représentation des variables\label{Fig:var}]{
\includegraphics[width=.4\columnwidth]{figures/pca_circle_12}}
\hspace*{\stretch{2}}
\subfigure[Représentation des individus.\label{Fig:ind}]{
\includegraphics[width=.5\columnwidth]{figures/pca_points_12}}
\hspace*{\stretch{1}}
\caption{Représentation sur le plan des deux premiers vecteurs propres.}
\end{center}
\end{figure}</p>
<p>L’interprétation de ce plan se fait séquentiellement, pour chaque axe et chaque nuage de points, en regardant les contributions à la formation des axes:
\begin{itemize}
\item Axe 1 :
\begin{itemize}
\item Variables :  les variables contribuant le plus à la formation de l’axe 1 sont celles dont les coordonnées sur cet axe sont proches de 1 en valeur absolue.
PAA et VIO sont très proches de la contribution moyenne, on les intègre donc dans l’interprétation de l’axe si elles vont dans le sens de l’interprétation que l’on peut en faire, sans elles. L’axe 1 oppose les individus consommant du pain ordinaire, des légumes secs (et éventuellement du vin ordinaire) à ceux qui consomment du raisin, du vin (éventuellement du pain) plus sophistiqué et des plats préparés. L’axe 1, et donc la première composante principale, mesure la répartition entre aliments ordinaires bon marché et aliments plus recherchés.</p>
<p>Toutes les variables sont bien représentées sur l’axe (la qualité de représentation est égale à la coordonnée au carré). D’un point de vue graphique, une variable bien représentée est proche du bord du cercle des corrélation et à proximité de l’axe. La première composante principale explique donc correctement tous les types de consommations alimentaires.</p>
<p>\item Individus : de même, les individus contribuant le plus à la formation de l’axe 1 sont ceux dont les coordonnées sur cet axe sont les plus élevées en valeur absolue. Le premier axe met donc en opposition les agriculteurs et les cadres supérieurs quant à leurs habitudes alimentaires. Les autres catégories socio-professionnelles, assez bien représentées sur l’axe à l’exception des inactifs (cf. contributions des individus sur l’axe 1), s’échelonnent suivant la hiérarchie habituelle. Elles sont bien expliquées par l’axe.
\end{itemize}
\item Axe 2 :
\begin{itemize}
\item Variables : L’axe 2 est défini par les variables POT et PAA. Compte tenu de la différence de contribution existant entre ces deux variables, de la contribution élevée de POT (55%), et de la qualité de représentation moyenne de PAA, la deuxième composante principale peut être considérée comme essentiellement liée à la consommation de pommes de terre. Les variables, à l’exception de POT et de PAA (dans une moindre mesure) sont assez mal représentées sur l’axe. La deuxième composante principale n’explique donc qu’un aspect très particulier de la consommation alimentaire.
\item Individus : Pour repérer les individus ayant une contribution significative, on compare les coordonnées des individus sur l’axe 2, à la racine de la deuxième valeur propre  =0,94, le signe donnant le sens de contribution.
\end{itemize}
\end{itemize}</p>
<p>L’axe 1 reflète donc l’opposition qui existe entre les catégories socio-professionnelles dans leur alimentation, opposant les CSP modestes qui consomment des produits basiques aux catégories favorisées qui consomment des produits plus recherchés. L’axe 2 reflète quant à lui la particularité des inactifs quant à leur alimentation, fortement composée de pommes de terre (un retour aux données d’origine vient confirmer cette conclusion).</p>
</div>
</div>
</div>
<div class="section" id="analyse-factorielle-des-correspondances">
<h2>Analyse Factorielle des correspondances<a class="headerlink" href="#analyse-factorielle-des-correspondances" title="Permalink to this headline">#</a></h2>
</div>
<div class="section" id="analyse-des-correspondances-multiples">
<h2>Analyse des correspondances multiples<a class="headerlink" href="#analyse-des-correspondances-multiples" title="Permalink to this headline">#</a></h2>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
            </main>
            <footer class="footer-article noprint">
                
    <!-- Previous / next buttons -->
<div class='prev-next-area'>
    <a class='left-prev' id="prev-link" href="TP1_statsDescriptives.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title">TP Statistiques descriptives</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="regression.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Régression</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
            </footer>
        </div>
    </div>
    <div class="footer-content row">
        <footer class="col footer"><p>
  
    By Vincent BARRA<br/>
  
      &copy; Copyright 2022.<br/>
</p>
        </footer>
    </div>
    
</div>


      </div>
    </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf"></script>


  </body>
</html>