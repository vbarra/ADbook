{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4081aa5f",
   "metadata": {},
   "source": [
    "# Rappels\n",
    "\n",
    "\n",
    "## Expérience aléatoire\n",
    "\n",
    "### Définitions\n",
    "````{prf:definition} Expérience aléatoire\n",
    ":label: expalea\n",
    "Une **expérience aléatoire** est une expérience dont on ne peut prévoir le résultat a priori. Répétée dans des conditions identiques, elle peut donner lieu à des résultats différents.\n",
    "````\n",
    "\n",
    "````{prf:example}\n",
    "- Le lancé de dé\n",
    "- les côtes exactes d'une pièce fabriquée dans un atelier\n",
    "````\n",
    "\n",
    "````{prf:definition} Issue\n",
    ":label: issue\n",
    "On appelle **issue** d'une expérience aléatoire l'un des résultats possibles de cette expérience\n",
    "````\n",
    "\n",
    "\n",
    "````{prf:definition} Univers des possibles\n",
    ":label: univers\n",
    "On appelle **univers des possibles** d'une expérience aléatoire l'ensemble  $\\Omega$ des issues de cette expérience.\n",
    "````\n",
    "\n",
    "````{prf:example}\n",
    "Lorsque l'on joue à pile ou face avec une pièce de monnaie, l'expérience a deux issues possibles et $\\Omega = \\{P,F\\}$.\n",
    "````\n",
    "L'univers des possibles n'est pas défini de manière unique, mais dépend de l'usage de l'experience. Par exemple, pour le lancer de deux dés, on peut être intéressé par :\n",
    "- le résultat du lancer, dans ce cas $\\Omega = \\{(1,1), (1,2), \\cdots (6,6)\\}$\n",
    "- la somme des deux faces et $\\Omega = [\\![2,12]\\!]$\n",
    "\n",
    "```{index} Evènement\n",
    "``` \n",
    "````{prf:definition} Evènement\n",
    ":label: evenement\n",
    "Etant donnée une expérience aléatoire, un **évènement** est une assertion vraie ou fausse suivant l'issue de l'expérience. C'est donc un sous-ensemble $E$ de $\\Omega$.\n",
    "````\n",
    "\n",
    "````{prf:example}\n",
    "- Dans l'expérience du lancer de deux dés, on peut s'intéresser à l'évènement \"la somme des deux faces est paire\" ou encore  \"la somme est supérieure à 7\".\n",
    "- Si l'expérience considérée concerne les jobs effectués sur une machine on peut considérer :\n",
    "1. $\\Omega=\\mathbb{N}$ et l'évènement \"le nombre de jobs ne dépasse pas 10\" : $E=[\\![0,5]\\!]$\n",
    "2. $\\Omega=\\mathbb{R}^*$ et  l'évènement \"le job dure plus de 15 s\" et $E=]15,+\\infty[$\n",
    "````\n",
    "Il existe certains évènements particuliers : \n",
    "- l'évènement dit certain : c'est l'univers des possibles (par exemple \"la somme des deux faces d'un lancer de deux dés est inférieure ou égale à 12\")\n",
    "- l'évènement impossible (\"la somme des deux faces d'un lancer de deux dés est supérieure ou égale à 20\")\n",
    "- l'évènement simple : tout singleton de $\\Omega$\n",
    "- l'évènement composé : tout sous-ensembme de $\\Omega$ de cardinalité au moins égale à 2.\n",
    "\n",
    "### Notation et opérations sur les évènements\n",
    "Les évènements peuvent être interprétés soit d'un point de vue ensembliste (Diagrammes de Venn), soit de manière équivalente d'un point de vue probabiliste.\n",
    "\n",
    "| **Notation**                      | **Interprétation probabiliste**           |\n",
    "|-------------------------------|---------------------------------------|\n",
    "| $\\omega$                      | issue possible, évènement élémentaire |\n",
    "| $A$                           | évènement                             |\n",
    "| $\\omega\\in A$                  | $\\omega$ réalise $A$                  |\n",
    "| $A\\subset B$                  | $A$ implique $B$                      |\n",
    "| $A\\cup B$                     | $A$ ou $B$                            |\n",
    "| $A\\cap B$                     | $A$ et $B$                            |\n",
    "| $\\bar A$                      | contraire de $A$                      |\n",
    "| $\\emptyset$                   | évènement impossible                  |\n",
    "| $\\Omega$                      | évènement certain                     |\n",
    "| $A\\cap B=\\emptyset$           | $A$ et $B$ incompatibles              |\n",
    "| $A\\setminus B = A\\cap \\bar B$ | $A$ et pas $B$                        |\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## Probabilités\n",
    "### Objectif\n",
    "L'objectif des probabilités est de donner une **mesure** à la chance qu'a un évènement de se réaliser lors d'une expérience aléatoire. Pour ce faire, on définit une fonction $P:\\Omega\\rightarrow [0,1]$ vérifiant certains axiomes et propriétés.\n",
    "\n",
    "```{index} Tribu\n",
    "``` \n",
    "\n",
    "````{prf:definition} Tribu\n",
    ":label: tribu\n",
    "Soit $T$ une famille d'évènements. Pour que $T$ soit probabilisable, il faut que :\n",
    "- $\\emptyset\\in T, \\Omega\\in T$\n",
    "- Si $A_i$ est une suite dans $T$ alors $\\cup_iA_i\\in T$ et $\\cap_iA_i\\in T$\n",
    "- Si $A\\in T$ alors $\\bar A\\in T$\n",
    "\n",
    "$T$ est une **tribu** et $(\\Omega,T)$ est un **espace probabilisable**.\n",
    "````\n",
    "En pratique, on choisit souvent la tribu engendrée par une famille de $n$ d'évènements $A_i$, qui est l'ensemble des parties de $\\Omega$ obtenues en effectuant l'union de $k$ évènements $A_i,i\\in [\\![1,n]\\!]$.\n",
    "\n",
    "````{prf:example}\n",
    "Dans le cas du lancer d'un dé, $\\Omega = \\{1,2,3,4,5,6\\}$, et : \n",
    "- la tribu engendrée par la famille d'évènements $\\{\\{1,3,5\\},\\{2,4,6\\}\\}$ est $\\{\\emptyset,\\{1,3,5\\},\\{2,4,6\\},\\Omega\\}$.\n",
    "- la tribu engendrée par la famille d'évènements $\\{\\{1\\},\\{2\\},\\{3\\},\\{4\\},\\{5\\},\\{6\\}\\}$ est l'ensemble des parties de $\\Omega$. Plus généralement, si $\\Omega$ est dénombrable, cette tribu est appelée **tribu discrète**.\n",
    "````\n",
    "On peut également s'intéresser, si $\\Omega=\\mathbb R$, à la tribu engendrée par les ouverts de $\\mathbb{R}$, on parle alors de **tribu borélienne**\n",
    "\n",
    "### Probabilité\n",
    "```{margin} A. Kolmogorov\n",
    "![](./images/kolmogorov.jpeg)\n",
    "```\n",
    "```{index} Probabilité\n",
    "``` \n",
    "```{prf:axiom} Axiomatique de Kolmogorov\n",
    ":label: axiomKolmo\n",
    "On appelle **probabilité** sur $(\\Omega,T)$ une application $P$ de $T$ dans [0,1] vérifiant :\n",
    "- $(\\forall A\\in T)\\; P(A)\\in[0,1]$\n",
    "- $P(\\Omega)=1$\n",
    "- Pour toute famille dénombrable $(A_i)$ d'évènements disjoints $P(\\displaystyle\\bigcup_i A_i) = \\displaystyle\\sum_iP(A_i)$\n",
    "```\n",
    "````{prf:property}\n",
    "- $P(\\emptyset)=0$\n",
    "- $(\\forall A)\\; P(\\bar A)=1-P(A)$\n",
    "- $(\\forall A,B)\\; P(A\\setminus B) = P(A)-P(A\\bigcap B)$\n",
    "- $(\\forall A,B)\\; P(A\\bigcup B) = P(A+P(B))-P(A\\bigcap B)$\n",
    "- $(\\forall A,B)$ si $A\\subset B$ alors $P(A)\\leq P(B)$\n",
    "- Pour toute famille dénombrable $(A_i)$ d'évènements quelconques $P(\\displaystyle\\bigcup_i A_i) \\leq \\displaystyle\\sum_iP(A_i)$\n",
    "````\n",
    "### Conditionnement\n",
    "Les probabilités **conditionnelles** intègrent une information supplémentaire sous la forme de l'observation de la réalisation d'un évènement donné.\n",
    "```{index} Probabilité ; conditionnelle\n",
    "``` \n",
    "````{prf:definition} Probabilité conditionnelle\n",
    "Soit $B$ un évènement de probabilité non nulle. On appelle **probabilité conditionnelle** de $A$ sachant $B$ le rapport \n",
    "\n",
    "$P(A\\mid B) = \\frac{P(A\\bigcap B)}{P(B)}$\n",
    "````\n",
    "$P(A\\mid B)$ représente la probabilité que $A$ se réalise sachant que $B$ est réalisé. \n",
    "\n",
    "Remarquons que l'on peut écrire $P(A\\bigcap B) = P(A\\mid B)P(B) = P(B\\mid A)P(A)$.\n",
    "\n",
    "````{prf:example}\n",
    "7\\% des français sont atteints d'un cancer du poumon. 70\\% des malades sont des fumeurs et 50\\% des français fument. On recherche la probabilité d'être atteint d'un cancer du poumon lorsque l'on est fumeur.\n",
    "L'évènement $A$ est \"avoir un cancer du poumon\", et $B$ est \"être fumeur\". D'après les données on a $P(A)$=0.07, $P(B)$ = 0.5 et $P(B\\mid A)$ = 0.7. \n",
    "On a alors $P(A\\mid B) = \\frac{P(A\\bigcap B)}{P(B)}$ avec $P(A\\bigcap B)=P(B\\mid A)P(A)$ d'où\n",
    "\n",
    "$P(B\\mid A)=\\frac{P(B\\mid A)P(A)}{P(B}$ = 0.098\n",
    "````\n",
    "\n",
    "### Indépendance\n",
    "```{index} Indépendance\n",
    "``` \n",
    "````{prf:definition} Indépendance\n",
    "Deux évènements $A$ et $B$ sont dits **indépendants** si et seulement si $P(A\\mid B) = P(A)$.\n",
    "````\n",
    "On a alors bien évidemment $P(A\\bigcap B) = P(A)P(B)$.\n",
    "\n",
    "```{prf:remark}\n",
    ":class: dropdown\n",
    "La notion d'indépendance est directement rattachée à $P$ : $A$ et $B$ peuvent être indépendants pour une probabilité donnée, mais pas pour une autre.\n",
    "```\n",
    "On peut généraliser la notion d'indépendance à une famille d'évènements $(A_i)_{i\\in[\\![1,n]\\!]}$ : on dira que les $A_i$ sont **mutuellement indépendants** si pour tout $I\\subset [\\![1,n]\\!]$\n",
    "\n",
    "$P\\left (\\displaystyle\\bigcap_{i\\in I} A_i\\right ) = \\displaystyle\\prod_{i\\in I} P(A_i)$\n",
    "\n",
    "L'indépendance mutuelle est plus forte que l'indépendance deux à deux.\n",
    "\n",
    "```{prf:remark}\n",
    ":class: dropdown\n",
    "La notion d'indépendance n'est pas une notion purement ensembliste. Deux évènements peuvent être indépendants pour une loi de probabilité et pas pour une autre. \n",
    "```\n",
    "\n",
    "### Théorème des probabilités totales\n",
    "\n",
    "```{prf:theorem}\n",
    "Soit $B_i$ un système complet d'évènements (qui forment donc une partition de $\\Omega$). Pour tout évènement $A$, on peut écrire \n",
    "\n",
    "$P(A) = \\displaystyle\\sum_i P(A\\bigcap B_i) = \\displaystyle\\sum_i P(A| B_i) P(B_i)$\n",
    "```\n",
    "\n",
    "\n",
    "### Règle de Bayes\n",
    "```{index} Bayes ; règle de \n",
    "``` \n",
    "\n",
    "A partir de l'égalité $P(A\\bigcap B) = P(A|B)P(B)=P(B|A)P(A)$, on définit la règle de Bayes\n",
    "\n",
    "$(\\forall A,B)\\quad P(B|A)=\\frac{P(A|B)P(B)}{P(A)}$\n",
    "\n",
    "\n",
    "Si $B_i$ est un système complet d'évènements, on a de plus \n",
    "\n",
    "$P(B_i|A)= \\frac{P(A|B_i)P(B_i)}{P(A)} = \\frac{P(A|B_i)P(B_i)}{\\displaystyle\\sum_k P(A|B_k)P(B_k)}$\n",
    "\n",
    "\n",
    "````{prf:example}\n",
    "Un fabricant de boulons a trois usines de fabrication situées à Amiens, Besançon et Clermont-Ferrand. Amiens fournit 25\\% de la production, Besançon 20\\% et Clermont-Ferrand 55\\%. Les boulons de 5mm représentent 20\\% des boulons produits à Amiens, 30\\% à Besançon et 15\\% à Clermont-Ferrand. On répond à la question suivante : sachant que le boulon acheté a une taille de 5mm, quelle est la probabilité qu'il soit produit à Clermont-Ferrand ?\n",
    "\n",
    "On note $B_1$ (respectivement $B_2,B_3$) l'évènement \"Le boulon est produit à Amiens (resp. Besançon, Clermont-Ferrand)\". On note également $A$ l'évènement \"Le boulon fait 5mm\". On cherche donc \n",
    "\n",
    "$P(B_3|A) = \\frac{P(A|B_3)P(B_3)}{P(A)}= \\frac{0.15*0.55}{0.1925}=0.428$. \n",
    "````\n",
    "On a calculé dans l'exemple une **probabilité a posteriori**, c'est à dire sachant une information supplémentaire (le boulon fait 5mm). La prise en compte de cette information modifie la valeur de la probabilité associée à $B_3$. La théorie des probabilités au travers de l'approche bayésienne est adaptée pour prendre en compte toute information nouvelle.\n",
    "\n",
    "\n",
    "## Variable aléatoire\n",
    "\n",
    "### Concept de variable aléatoire\n",
    "Soit un espace probabilisé $(\\Omega, T,P)$, avec $\\Omega$ = (Pile,Face). On considère la loi de probabilité $P$ telle que : $(\\forall \\omega\\in\\Omega)\\; P(\\omega)=\\frac12$\n",
    "\n",
    "```{index} Variable aléatoire\n",
    "``` \n",
    "````{prf:definition} Variable aléatoire\n",
    "Une variable aléatoire est une application $X:\\Omega\\rightarrow E$ (on prendra $E=\\mathbb R$)\n",
    "```` \n",
    "\n",
    "Pour obtenir la probabilité d'une valeur quelconque image par $X$, il suffit de dnombrer les $\\omega$ qui réalisent cette valeur. Ici, $P(X=1)= P(\\{Pile\\}) = \\frac12$. On dit que l'on transporte la loi de probabilité de $\\Omega$ sur $E$ par l'application $X$.\n",
    "\n",
    "Les éléments de $E$ sont les **réalisations** de la variable aléatoire.\n",
    "\n",
    "````{prf:example}\n",
    "Si l'expérience consiste à observer le résultat du tirage de deux dés à 6 faces, $\\Omega = \\{(1,1), (1,2), \\cdots (6,5), (6,6)\\}$, on considère la loi de probabilité telle que $(\\forall \\omega\\in\\Omega)\\; P(\\omega)=\\frac{1}{36}$. \n",
    "\n",
    "Si l'application $X$ réalise la somme des deux éléments de $\\omega\\in\\Omega$, alors on a par exemple $P(X=3)= P(\\{(1,2),(2,1)\\}) = \\frac{2}{36}$, ou encore $P(X=5)= P(\\{(1,4),(2,3),(3,2),(4,1)\\}) = \\frac{4}{36}$\n",
    "````\n",
    "\n",
    "### Variable aléatoire mesurable\n",
    "On définit sur $E$ une tribu $T'$.  $(E,T')$ est alors un espace probabilisable, et tout élément $B$ de $T'$ est un évènement. On note alors $X^{-1}(B) = \\{\\omega\\in\\Omega,\\; X(\\omega)\\in B\\}$\n",
    "\n",
    "```{index} Variable aléatoire ; mesurable\n",
    "``` \n",
    "````{prf:definition} Variable aléatoire mesurabe\n",
    "Une variable aléatoire $X$ est dite mesurable  si et seulement si : $(\\forall B\\in T')\\; X^{-1}(B)\\in T$\n",
    "```` \n",
    "\n",
    "Dans les deux exemples précédents, on a par exemple $X^{-1}(1)= \\{Pile\\}$ ou encore $X^{-1}(3) = \\{(1,2),(2,1)\\}$ et $P(X=3)=P(X^{-1}(3)) = \\frac{2}{36}$.\n",
    "\n",
    "```{index} Distribution de probabilité\n",
    "``` \n",
    "```{index} Probabilité ; distribution de \n",
    "``` \n",
    "On note souvent $P_X(B) = P(X^{-1}(B))=P(\\{\\omega / X(\\omega)\\in B\\})$ et on l'appelle **probabilité image** de $P$ par $X$. En calculant la probabilité de chaque réalisation de la variable aléatoire $X$, on peut en déduire la **loi de probabilité** (ou **distribution**) de $X$.\n",
    "\n",
    "- Pour une variable aléatoire discrète $X$, la loi de probabilité est donc $P_X(x_i)= P(X=x_i) = P(\\{\\omega / X(\\omega)=x_i\\})$. $P_X$ est appelée **masse ponctuelle**\n",
    "```{index} Probabilité ; densité de \n",
    "``` \n",
    "```{index} Densité de probabilité\n",
    "``` \n",
    "- Pour une variable aléatoire continue $X$, la loi de probabilité est donc $f_X(x)dx = P(x\\leq X\\leq x+dx) = P(\\{\\omega /x\\leq X(\\omega)\\leq x+dx\\})$. $f_X$ est appelée **densité de probabilité**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f2a7b842",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'numpy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [1], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmath\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m floor\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mrandom\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m random\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtirage\u001b[39m():\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'numpy'"
     ]
    }
   ],
   "source": [
    "from math import floor\n",
    "from random import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def tirage():\n",
    "    d1=floor(6*random()+1)   \n",
    "    d2=floor(6*random()+1)  \n",
    "    return d1+d2 -1          \n",
    "\n",
    "x = np.arange(0,12)+1\n",
    "f = np.zeros(12)\n",
    "n=10000                       \n",
    "for i in range(n):        \n",
    "    f[tirage() ] += 1\n",
    "f=f/n                      \n",
    "\n",
    "plt.plot( x, f, 'o' )   \n",
    "plt.vlines( x, 0, f )   \n",
    "plt.ylim( bottom=0 ) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f9e693b",
   "metadata": {},
   "source": [
    "```{prf:definition} Fonction de répartition\n",
    "```{index} Fonction de répartition\n",
    "``` \n",
    "La fonction de répartition d'une variable aléatoire $X$ est l'application $F_X$ de $\\mathbb R$ dans [0,1] telle que $F_X(x) = P(X\\leq x)$.\n",
    "```\n",
    "\n",
    "$F_X$ est donc monotone croissante, continue à droite et on a en particulier :  \n",
    "- $P(a\\leq X\\leq b) = F_X(b)-F_X(a)$\n",
    "- $P(X>x) = 1-P(X\\leq x) = 1-F_X(x)$\n",
    "\n",
    "\n",
    "```{code-cell} ipython3\n",
    "from math import floor\n",
    "from random import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def tirage():\n",
    "    d1=floor(6*random()+1)   \n",
    "    d2=floor(6*random()+1)  \n",
    "    return d1+d2 -1          \n",
    "\n",
    "x = np.arange(0,12)+1\n",
    "f = np.zeros(12)\n",
    "n=10000                       \n",
    "for i in range(n):        \n",
    "    f[tirage() ] += 1\n",
    "f=f/n     \n",
    "\n",
    "data = np.arange(0, 14)\n",
    "fn = np.insert(np.cumsum(f), 0, 0)\n",
    "\n",
    "plt.figure(figsize=(10,5))          \n",
    "plt.subplot(121)\n",
    "plt.plot( x, f, 'o' )   \n",
    "plt.vlines( x, 0, f )   \n",
    "plt.ylim( bottom=0 ) \n",
    "plt.title(\"Distribution\")\n",
    "plt.subplot(122)\n",
    "\n",
    "plt.hlines(y=fn, xmin=data[:-1], xmax=data[1:],\n",
    "          color='red', zorder=1)\n",
    "plt.vlines(x=data[1:-1], ymin=fn[:-1], ymax=fn[1:], color='red',\n",
    "          linestyle='dashed', zorder=1)\n",
    "plt.ylim( bottom=0 ) \n",
    "plt.title(\"Fonction de répartition\")\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "La notion de variable aléatoire est ainsi une formalisation de la notion de grandeur variant selon le résultat d'une expérience aléatoire. On peut alors préciser et formaliser la définition précédente.\n",
    "\n",
    "````{prf:definition} Variable aléatoire\n",
    "Une variable aléatoire est une application mesurable $X:(\\Omega,T,P) \\rightarrow (E,T')$ \n",
    "```` \n",
    "\n",
    "```{prf:remark}\n",
    ":class: dropdown\n",
    "- Si $E=\\mathbb N$, on parle de variable aléatoire (réelle) discrète\n",
    "- Si $E=\\mathbb R$, on parle de variable aléatoire (réelle) continue. $T'$ est alors la tribu **borélienne**\n",
    "- Si $E=\\mathbb N^n$ ou $E=\\mathbb R^n$n on parle de **vecteur aléatoire** de dimension $n$.\n",
    "```\n",
    "\n",
    "### Caractéristiques des variables aléatoires\n",
    "Une loi de probabilité est caractérisée par un certain nombre de grandeurs :\n",
    "- sa valeur centrale\n",
    "- sa dispersion\n",
    "- sa forme\n",
    "\n",
    "#### Espérance mathématique d'une variable aléatoire\n",
    "```{index} Espérance\n",
    "```\n",
    "````{prf:definition} Espérance\n",
    "Soit $X$ une variable aléatoire. On définit l'espérance mathématique de $X$, et on note $\\mathbb E(X)$ par :\n",
    "- $\\mathbb E(X) = \\mu_X = \\displaystyle\\sum_{x_i} x_iP(X=x_i)= \\displaystyle\\sum_{x_i} x_i P_X(x_i)$ si $X$ est discrète et si la somme converge.\n",
    "- $\\mathbb E(X) = \\mu_X =\\int_x xdP(x) = \\int_x x f_X(x) dx$ si $X$ est continue et si l'intégrale converge.\n",
    "````\n",
    "\n",
    "$\\mathbb E(X)$ est la moyenne arithmétique (également notée $\\mu_X$) des différentes valeurs prises par $X$ pondérées par leur probabilité.\n",
    "\n",
    "On dira que $X$ est **centrée** si $\\mathbb{E}(X)=0$.\n",
    "\n",
    "````{prf:example}\n",
    "Pour l'expérience d'un lancer de dé à 6 faces  : $\\mathbb E(X) = \\mu_X = \\displaystyle\\sum_{i=1}^6 i\\frac16 = \\frac72$\n",
    "````\n",
    "\n",
    "````{prf:property}\n",
    "- $(\\forall a\\in\\mathbb{R})\\; \\mathbb{E}(a)= a$\n",
    "- $(\\forall a\\in\\mathbb{R})\\; \\mathbb{E}(aX)= a\\mathbb{E}(X)$\n",
    "- $(\\forall a\\in\\mathbb{R})\\; \\mathbb{E}(X+a) = \\mathbb{E}(X) +a$\n",
    "````\n",
    "\n",
    "#### Moment d'une fonction d'une variable aléatoire\n",
    "```{index} Moment\n",
    "```\n",
    "Soit $\\phi$ l'application qui associe à toute variable aléatoire $X$ la variable aléatoire $Y=\\phi(X)$.\n",
    "\n",
    "````{prf:definition} Moment\n",
    "Le moment  $\\mathbb{E}[\\phi(X)]$ de la fonction $\\phi$ de la variable aléatoire $X$ est égal à :\n",
    "- $\\mathbb{E}[\\phi(X)] = \\displaystyle\\sum_{x_i} \\phi(x_i)P_X(x_i)$ si $X$ est discrète\n",
    "- $\\mathbb{E}[\\phi(X)] = \\int_x \\phi(x) f_X(x)dx$ si $X$ est continue\n",
    "```` \n",
    "```{index} Moment ; d'ordre k\n",
    "```\n",
    "````{prf:definition} Moment d'ordre $k$\n",
    "Le moment d'ordre $k$ d'une variable aléatoire $X$ est égal à :\n",
    "- $\\mathbb{E}(X^k) = \\displaystyle\\sum_{x_i} x_i^k P_X(x_i)$ si $X$ est discrète\n",
    "- $ \\mathbb{E}(X^k) = \\int_x x^k f_X(x)dx$ si $X$ est continue\n",
    "```` \n",
    "\n",
    "Le moment d'ordre $k$ est donc un cas particulier avec $Y=X^k$.\n",
    "\n",
    "```{prf:remark}\n",
    ":class: dropdown\n",
    "L'espérance $\\mathbb{E}(X)$ est le moment d'ordre 1.\n",
    "``` \n",
    "\n",
    "```{index} Moment ; centré\n",
    "```\n",
    "````{prf:definition} Moment centré d'ordre $k$\n",
    "On appelle moment centré d'ordre $k$ la quantité $\\mathbb{E}\\left [(X-\\mathbb{E}(X))^k \\right]$\n",
    "````\n",
    "Ainsi : \n",
    "- pour une variable aléatoire discrète $X$, $\\mathbb{E}\\left [(X-\\mathbb{E}(X))^k \\right] = \\displaystyle\\sum_{x_i} (x_i-\\mathbb{E}(X))^k P_X(x_i) = \\displaystyle\\sum_{x_i} (x_i-\\mu_X)^k P_X(x_i)$\n",
    "- pour une variable aléatoire continue $X$, $\\mathbb{E}\\left [(X-\\mathbb{E}(X))^k \\right] = \\int_x (x-\\mathbb{E}(X))^k f_X(x)dx = \\int_x (x-\\mu_X)^k f_X(x)dx$\n",
    "\n",
    "#### Variance d'une variable aléatoire\n",
    "```{index} Variance\n",
    "```\n",
    "```{index} Ecart-type\n",
    "```\n",
    "Pour $k$=2, le moment centré d'ordre 2 est appelé la **variance** et est noté $\\mathbb{V}(X)$. La racine carrée de la variance est **l'écart type** et est noté $\\sigma_X$. On a donc $\\sigma_X^2=\\mathbb{V}(X)$.\n",
    "\n",
    "````{prf:proposition} Formule de Koenig\n",
    "$\\mathbb{V}(X) = \\mathbb{E}(X^2)-\\mu_X^2$ \n",
    "````\n",
    "En effet, $\\mathbb{E}\\left [(X-\\mu_X)^2 \\right] = \\mathbb{E}\\left [(X^2-2\\mu_XX+\\mu_X^2 \\right] = \\mathbb{E}(X^2)-2\\mu_X\\mathbb{E}(X)+\\mu_X^2$.\n",
    "\n",
    "````{prf:property}\n",
    "- $(\\forall a,b\\in\\mathbb{R})\\; \\mathbb{V}(aX+b)= a^2\\mathbb{V}(X)$\n",
    "- $(\\forall a\\in\\mathbb{R})\\; \\mathbb{E}\\left [(X-a)^2\\right ] = \\mathbb V(X) +(\\mathbb{E}(X)-a)^2$ (théorème de Huygens)\n",
    "- $\\forall k>0\\; P(|X-\\mathbb{E}(X)|\\geq k\\sigma_X)\\leq \\frac{1}{k^2}$ (inégalité de Bienaymé-Tchebychev)\n",
    "````\n",
    "\n",
    "On dira que la variable aléatoire $X$ est **réduite** (ou **normée**) si $\\mathbb{V}(X)=1$.\n",
    "\n",
    "#### Moments d'ordre supérieur\n",
    "```{index} Skewness\n",
    "```\n",
    "```{index} Kurtosis\n",
    "```\n",
    "On considère également souvent les moments d'ordre 3 (coefficient d'asymétrie ou skewness) et 4 (coefficient d'applatissement ou kurtosis)."
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "md:myst",
   "text_representation": {
    "extension": ".md",
    "format_name": "myst"
   }
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "source_map": [
   11,
   256,
   278
  ]
 },
 "nbformat": 4,
 "nbformat_minor": 5
}