{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TP ACP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['axes.labelsize'] = 12\n",
    "plt.rcParams['xtick.labelsize'] = 12\n",
    "plt.rcParams['ytick.labelsize'] = 12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Définition de quelques outils \n",
    "\n",
    "On définit ici quelques fonctions utiles pour l'affichage des résultats, non présents dans sklearn :\n",
    "- screeplot : variance expliquée en fonction des composantes principales\n",
    "- CercleCorrelation : affichage du cercle des corrélations\n",
    "- biplot : affichage simultané des individus et des variables dans un plan principal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def screeplot(Xtr, displayx = True):\n",
    "    y = np.std(Xtr, axis=0)**2\n",
    "    x = np.arange(len(y)) + 1\n",
    "    plt.plot(x, y, \"o-\")\n",
    "    if displayx :\n",
    "        plt.xticks(x, [\"CP \"+str(i) for i in x], rotation=60)\n",
    "    plt.ylabel(\"Variance\")\n",
    "    plt.xlabel(\"CP\")\n",
    "    plt.title(\"Scree Plot\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CercleCorrelation(pca,np1,np2,data,nom_features):\n",
    "    plt.Circle((0,0),radius=10, color='b', fill=False)\n",
    "    circle1=plt.Circle((0,0),radius=1, color='b', fill=False)\n",
    "    fig = plt.gcf()\n",
    "    fig.gca().add_artist(circle1)\n",
    "\n",
    "    for idx in range(len(nom_features)):\n",
    "        str1 = \"CP\" + str(np1)\n",
    "        str2 = \"CP\" + str(np2)\n",
    "        x = pca.components_[np1][idx]\n",
    "        y = pca.components_[np2][idx]\n",
    "        plt.plot([0.0,x],[0.0,y],'k-')\n",
    "        plt.plot(x, y, 'rx')\n",
    "        plt.annotate(nom_features[idx], xy=(x,y))\n",
    "    plt.xlabel(str1 +\" (%s%%)\" % str(pca.explained_variance_ratio_[np1])[:4].lstrip(\"0.\"))\n",
    "    plt.ylabel(str2 +\" (%s%%)\"% str(pca.explained_variance_ratio_[np2])[:4].lstrip(\"0.\"))\n",
    "    plt.xlim((-1,1))\n",
    "    plt.ylim((-1,1))\n",
    "    plt.title(\"Cercle des corrélations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def biplot(pca,np1,np2,data,nom_features):  \n",
    "    cp1 = pca.components_[np1]\n",
    "    cp2 = pca.components_[np2]\n",
    "    xs = pca.transform(data)[:,np1] \n",
    "    ys = pca.transform(data)[:,np2]\n",
    "    for i in range(len(cp1)):\n",
    "        plt.arrow(0, 0, cp1[i]*max(xs), cp2[i]*max(ys),\n",
    "                  color='r', width=0.0005, head_width=0.0025)\n",
    "        plt.text(cp1[i]*max(xs)*1.2, cp2[i]*max(ys)*1.2,\n",
    "                 nom_features[i], color='r')\n",
    "\n",
    "    for i in range(len(xs)):\n",
    "        plt.plot(xs[i], ys[i], 'bo')\n",
    "        plt.text(xs[i]*1.2, ys[i]*1.2, i, color='b')\n",
    "    plt.xlabel(\"CP\" + str(np1) +\" (%s%%)\" % str(pca.explained_variance_ratio_[np1])[:4].lstrip(\"0.\"))\n",
    "    plt.ylabel(\"CP\" + str(np2) +\" (%s%%)\"% str(pca.explained_variance_ratio_[np2])[:4].lstrip(\"0.\"))\n",
    "    plt.title(\"Biplot individus / variables sur les CP\" +str(np1)+\" et \" + str(np2))\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercice 1 : étude de propriétés de vins\n",
    "Le fichier vins.csv contient les résultats d'analyses chimiques de trois classes de vins italiens, provenant de la même région mais de viticulteurs différents. Les analyses portent sur la quantification de 13 indices quantitatifs continus reliés aux vins : degré d'alcool, acide malique, présence de cendres, alcalinité des cendres, magnésium, phénols totaux, flavonoïdes, phénols non flavanoïdes, proanthocyanidines, intensité de la couleur du vin, teinte, OD280/OD315 des vins dilués et proline. Le fichier décrit un vin par ligne (sa classe et ses 13 attributs)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "vins = pd.read_csv(\"./data/vins.csv\",delimiter=\",\",header=None)\n",
    "cat_vins = vins.loc[: , 0]\n",
    "features_vins = vins.loc[:,1:vins.shape[1]]\n",
    "nom_features = ['% alcool', 'acide malique', 'cendres', 'alcalinité', 'magnésium', 'phénols' , \n",
    "                'flavonoïdes', 'non flavanoïdes', 'proanthocyanidines', 'couleur', 'teinte', \n",
    "                'OD280/OD315','proline']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ===== Votre travail : =====\n",
    "\n",
    "### Appliquer une [ACP](https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html) à ces données, de deux manières :\n",
    "\n",
    "- sur les données brutes du tableau\n",
    "- sur les données normalisées, en utilisant la fonction [StandardScaler](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html) de ScikitLearn\n",
    "    \n",
    "### Pour chacune de ces analyses :\n",
    "- déterminer si l'analyse est pertinente et si oui pourquoi\n",
    "- Si elle l'est effectivement, déterminer le nombre de composantes principales à retenir, interpréter les axes principaux, afficher le(s) plan(s) principal(aux) et interpréter graphiquement les résultats\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercice 2 : étude de données image\n",
    "Nous étudions des données image, représentant des chiffres manuscrits. Nous utilisons pour cela la base de données standard MNIST (Mixed National Institute of Standards and Technology), très employée pour le test de nouveaux algorithmes de reconnaissance de ces chiffres. Elle est composée de 60000 images d’apprentissage et 10000 images de test. Les images en noir et blanc, normalisées centrées de 28 pixels de côté."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [6]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdatasets\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m fetch_openml\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m Xmnist, ymnist \u001b[38;5;241m=\u001b[39m \u001b[43mfetch_openml\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmnist_784\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mversion\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_X_y\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mplanche\u001b[39m(X):\n\u001b[1;32m      6\u001b[0m     plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m9\u001b[39m,\u001b[38;5;241m9\u001b[39m))\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/sklearn/datasets/_openml.py:958\u001b[0m, in \u001b[0;36mfetch_openml\u001b[0;34m(name, version, data_id, data_home, target_column, cache, return_X_y, as_frame)\u001b[0m\n\u001b[1;32m    956\u001b[0m \u001b[38;5;66;03m# obtain the data\u001b[39;00m\n\u001b[1;32m    957\u001b[0m url \u001b[38;5;241m=\u001b[39m _DATA_FILE\u001b[38;5;241m.\u001b[39mformat(data_description[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfile_id\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m--> 958\u001b[0m bunch \u001b[38;5;241m=\u001b[39m \u001b[43m_download_data_to_bunch\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    959\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    960\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    961\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_home\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    962\u001b[0m \u001b[43m    \u001b[49m\u001b[43mas_frame\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mbool\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mas_frame\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    963\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfeatures_list\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeatures_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    964\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    965\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget_columns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtarget_columns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    966\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_columns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_columns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    967\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmd5_checksum\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_description\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmd5_checksum\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    968\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    970\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m return_X_y:\n\u001b[1;32m    971\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m bunch\u001b[38;5;241m.\u001b[39mdata, bunch\u001b[38;5;241m.\u001b[39mtarget\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/sklearn/datasets/_openml.py:655\u001b[0m, in \u001b[0;36m_download_data_to_bunch\u001b[0;34m(url, sparse, data_home, as_frame, features_list, data_columns, target_columns, shape, md5_checksum)\u001b[0m\n\u001b[1;32m    652\u001b[0m             y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    653\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m X, y, frame, nominal_attributes\n\u001b[0;32m--> 655\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43m_retry_with_clean_cache\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_home\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_load_arff_response\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    656\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    657\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_home\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    658\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    659\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencode_nominal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mas_frame\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    660\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparse_arff\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparse_arff\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    661\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmd5_checksum\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmd5_checksum\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    662\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    663\u001b[0m X, y, frame, nominal_attributes \u001b[38;5;241m=\u001b[39m postprocess(\u001b[38;5;241m*\u001b[39mout)\n\u001b[1;32m    665\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m Bunch(\n\u001b[1;32m    666\u001b[0m     data\u001b[38;5;241m=\u001b[39mX,\n\u001b[1;32m    667\u001b[0m     target\u001b[38;5;241m=\u001b[39my,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    671\u001b[0m     target_names\u001b[38;5;241m=\u001b[39mtarget_columns,\n\u001b[1;32m    672\u001b[0m )\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/sklearn/datasets/_openml.py:61\u001b[0m, in \u001b[0;36m_retry_with_clean_cache.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kw)\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw)\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 61\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m HTTPError:\n\u001b[1;32m     63\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/sklearn/datasets/_openml.py:529\u001b[0m, in \u001b[0;36m_load_arff_response\u001b[0;34m(url, data_home, return_type, encode_nominal, parse_arff, md5_checksum)\u001b[0m\n\u001b[1;32m    523\u001b[0m stream \u001b[38;5;241m=\u001b[39m _stream_checksum_generator(response)\n\u001b[1;32m    525\u001b[0m arff \u001b[38;5;241m=\u001b[39m _arff\u001b[38;5;241m.\u001b[39mload(\n\u001b[1;32m    526\u001b[0m     stream, return_type\u001b[38;5;241m=\u001b[39mreturn_type, encode_nominal\u001b[38;5;241m=\u001b[39mencode_nominal\n\u001b[1;32m    527\u001b[0m )\n\u001b[0;32m--> 529\u001b[0m parsed_arff \u001b[38;5;241m=\u001b[39m \u001b[43mparse_arff\u001b[49m\u001b[43m(\u001b[49m\u001b[43marff\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    531\u001b[0m \u001b[38;5;66;03m# consume remaining stream, if early exited\u001b[39;00m\n\u001b[1;32m    532\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m stream:\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/sklearn/datasets/_openml.py:361\u001b[0m, in \u001b[0;36m_convert_arff_data_dataframe\u001b[0;34m(arff, columns, features_dict)\u001b[0m\n\u001b[1;32m    359\u001b[0m dfs \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    360\u001b[0m dfs\u001b[38;5;241m.\u001b[39mappend(first_df[columns_to_keep])\n\u001b[0;32m--> 361\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m data \u001b[38;5;129;01min\u001b[39;00m _chunk_generator(arff[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\"\u001b[39m], chunksize):\n\u001b[1;32m    362\u001b[0m     dfs\u001b[38;5;241m.\u001b[39mappend(pd\u001b[38;5;241m.\u001b[39mDataFrame(data, columns\u001b[38;5;241m=\u001b[39marff_columns)[columns_to_keep])\n\u001b[1;32m    363\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat(dfs, ignore_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/sklearn/utils/__init__.py:705\u001b[0m, in \u001b[0;36m_chunk_generator\u001b[0;34m(gen, chunksize)\u001b[0m\n\u001b[1;32m    702\u001b[0m \u001b[38;5;124;03m\"\"\"Chunk generator, ``gen`` into lists of length ``chunksize``. The last\u001b[39;00m\n\u001b[1;32m    703\u001b[0m \u001b[38;5;124;03mchunk may have a length less than ``chunksize``.\"\"\"\u001b[39;00m\n\u001b[1;32m    704\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 705\u001b[0m     chunk \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mislice\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgen\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    706\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m chunk:\n\u001b[1;32m    707\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m chunk\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/sklearn/externals/_arff.py:461\u001b[0m, in \u001b[0;36mDenseGeneratorData.decode_rows\u001b[0;34m(self, stream, conversors)\u001b[0m\n\u001b[1;32m    460\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecode_rows\u001b[39m(\u001b[38;5;28mself\u001b[39m, stream, conversors):\n\u001b[0;32m--> 461\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m row \u001b[38;5;129;01min\u001b[39;00m stream:\n\u001b[1;32m    462\u001b[0m         values \u001b[38;5;241m=\u001b[39m _parse_values(row)\n\u001b[1;32m    464\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(values, \u001b[38;5;28mdict\u001b[39m):\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/sklearn/externals/_arff.py:864\u001b[0m, in \u001b[0;36mArffDecoder._decode.<locals>.stream\u001b[0;34m()\u001b[0m\n\u001b[1;32m    863\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstream\u001b[39m():\n\u001b[0;32m--> 864\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m row \u001b[38;5;129;01min\u001b[39;00m s:\n\u001b[1;32m    865\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_current_line \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    866\u001b[0m         row \u001b[38;5;241m=\u001b[39m row\u001b[38;5;241m.\u001b[39mstrip()\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/sklearn/datasets/_openml.py:519\u001b[0m, in \u001b[0;36m_load_arff_response.<locals>._stream_checksum_generator\u001b[0;34m(response)\u001b[0m\n\u001b[1;32m    518\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_stream_checksum_generator\u001b[39m(response):\n\u001b[0;32m--> 519\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m response:\n\u001b[1;32m    520\u001b[0m         actual_md5_checksum\u001b[38;5;241m.\u001b[39mupdate(line)\n\u001b[1;32m    521\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m line\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/usr/local/Cellar/python@3.9/3.9.13/Frameworks/Python.framework/Versions/3.9/lib/python3.9/gzip.py:398\u001b[0m, in \u001b[0;36mGzipFile.readline\u001b[0;34m(self, size)\u001b[0m\n\u001b[1;32m    396\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mreadline\u001b[39m(\u001b[38;5;28mself\u001b[39m, size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m    397\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_not_closed()\n\u001b[0;32m--> 398\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_buffer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreadline\u001b[49m\u001b[43m(\u001b[49m\u001b[43msize\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/Cellar/python@3.9/3.9.13/Frameworks/Python.framework/Versions/3.9/lib/python3.9/_compression.py:67\u001b[0m, in \u001b[0;36mDecompressReader.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mreadinto\u001b[39m(\u001b[38;5;28mself\u001b[39m, b):\n\u001b[0;32m---> 67\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mmemoryview\u001b[39m(b) \u001b[38;5;28;01mas\u001b[39;00m view, view\u001b[38;5;241m.\u001b[39mcast(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mB\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m byte_view:\n\u001b[1;32m     68\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m(byte_view))\n\u001b[1;32m     69\u001b[0m         byte_view[:\u001b[38;5;28mlen\u001b[39m(data)] \u001b[38;5;241m=\u001b[39m data\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "import matplotlib\n",
    "Xmnist, ymnist = fetch_openml('mnist_784', version=1, return_X_y=True)\n",
    "\n",
    "def planche(X):\n",
    "    plt.figure(figsize=(9,9))\n",
    "    exemples = (1-np.r_[X[:12000:600], X[13000:30600:600], X[30600:60000:590]]/255)\n",
    "    size = 28\n",
    "    taille = 10\n",
    "    taille = min(len(exemples), taille)\n",
    "    images = [exemple.reshape(size,size) for exemple in exemples]\n",
    "    n_rows = (len(exemples) - 1) // taille + 1\n",
    "    row_images = []\n",
    "    n_empty = n_rows * taille - len(exemples)\n",
    "    images.append(np.zeros((size, size * n_empty)))\n",
    "    for row in range(n_rows):\n",
    "        rimages = images[row * taille : (row + 1) * taille]\n",
    "        row_images.append(np.concatenate(rimages, axis=1))\n",
    "    image = np.concatenate(row_images, axis=0)\n",
    "    plt.imshow(image, cmap = matplotlib.cm.binary)\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n",
    "\n",
    "planche(Xmnist)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'ACP est ici utilisée pour réduire la représentation des données (un point ici est un vecteur de 28*28=784, l'espace original est donc $\\mathbb{R}^{784}$). Intuitivement, on comprend bien que, de nombreux pixels étant noirs et communs à toutes les images, 784 dimensions sont inutiles.\n",
    "\n",
    "Pour ne pas surcharger la visualisation, vous utiliserez un sous-ensemble de ${\\tt nb\\_digits}$ images de MNIST (code donné)\n",
    "### ===== Votre travail consiste à : =====\n",
    "- Calculer une ACP de ces données (normalisées ? non normalisées ? jusitifier)\n",
    "- Projeter les individus dans un  plan principal (ou dans un expace 3D de composantes principales) et commenter le résultat (codes de l'affichage fournis). \n",
    "- Inférer sur le nombre de composantes principales nécessaires pour expliquer les données initiales\n",
    "- Essayer de reconstruire une image donnée à partir de ses coordonnées sur les $n$ premières composantes principales (faire varier $n$) et voir la qualité de la reconstruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utilisation d'un sous-ensemble de Xmnist (pour ne pas surcharger la visualisation)\n",
    "ymnist=ymnist.astype(int)\n",
    "nb_digits = 10000\n",
    "s = np.arange(Xmnist.shape[0])\n",
    "np.random.shuffle(s)\n",
    "X0=Xmnist[s]\n",
    "y0=ymnist[s]\n",
    "Xdata = X0[:nb_digits]\n",
    "ydata = y0[:nb_digits]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction d'affichage sur le plan principal (n1,n2)\n",
    "# x : coordonnées des individus projetés sur les composantes principales\n",
    "# y : label de l'individu (c'est à dire le chiffre lu sur l'image)\n",
    "# n1,n2 : numéro des composantes principales (0 : première CP,  : 2e CP...)\n",
    "def AfficheCP2D (x,y, n1,n2):\n",
    "    fig = plt.figure(figsize=(10, 10))\n",
    "    plt.scatter(x[:, n1], x[:, n2], c=y[:], edgecolor='none', alpha=0.5,cmap=plt.get_cmap('jet', 10), s=5)\n",
    "    plt.xlabel('Composante principale '+str(n1+1))\n",
    "    plt.ylabel('Composante principale '+str(n2+1))\n",
    "    plt.title('MNIST')\n",
    "    plt.colorbar()\n",
    "\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "def AfficheCP3D(x,y, n1,n2,n3):\n",
    "    fig = plt.figure(figsize=(10, 10))\n",
    "    ax = fig.add_subplot(111, projection='3d',elev=30, azim=134)\n",
    "    ax.scatter(x[:, n1], x[:, n2], x[:, n3], c=y, cmap=plt.cm.get_cmap('jet', 30),edgecolor='k')\n",
    "    ax.set_xlabel('Composante principale '+str(n1+1))\n",
    "    ax.set_ylabel('Composante principale '+str(n2+1))\n",
    "    ax.set_zlabel('Composante principale '+str(n3+1))\n",
    "    ax.set_title('MNIST')\n",
    "    ax.w_xaxis.set_ticklabels([])\n",
    "    ax.w_yaxis.set_ticklabels([])\n",
    "    ax.w_zaxis.set_ticklabels([])\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}