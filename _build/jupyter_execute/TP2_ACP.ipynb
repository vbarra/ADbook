{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TP ACP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3\u001b[0m\r\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3.11 -m pip install --upgrade pip\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "# n'exécuter qu'une fois\n",
    "!pip3 install sklearn numpy matplotlib --q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['axes.labelsize'] = 12\n",
    "plt.rcParams['xtick.labelsize'] = 12\n",
    "plt.rcParams['ytick.labelsize'] = 12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Définition de quelques outils \n",
    "\n",
    "On définit ici quelques fonctions utiles pour l'affichage des résultats, non présents dans sklearn :\n",
    "- screeplot : variance expliquée en fonction des composantes principales\n",
    "- CercleCorrelation : affichage du cercle des corrélations\n",
    "- biplot : affichage simultané des individus et des variables dans un plan principal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def screeplot(Xtr, displayx = True):\n",
    "    y = np.std(Xtr, axis=0)**2\n",
    "    x = np.arange(len(y)) + 1\n",
    "    plt.plot(x, y, \"o-\")\n",
    "    if displayx :\n",
    "        plt.xticks(x, [\"CP \"+str(i) for i in x], rotation=60)\n",
    "    plt.ylabel(\"Variance\")\n",
    "    plt.xlabel(\"CP\")\n",
    "    plt.title(\"Scree Plot\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CercleCorrelation(pca,np1,np2,data,nom_features):\n",
    "    plt.Circle((0,0),radius=10, color='b', fill=False)\n",
    "    circle1=plt.Circle((0,0),radius=1, color='b', fill=False)\n",
    "    fig = plt.gcf()\n",
    "    fig.gca().add_artist(circle1)\n",
    "\n",
    "    for idx in range(len(nom_features)):\n",
    "        str1 = \"CP\" + str(np1)\n",
    "        str2 = \"CP\" + str(np2)\n",
    "        x = pca.components_[np1][idx]\n",
    "        y = pca.components_[np2][idx]\n",
    "        plt.plot([0.0,x],[0.0,y],'k-')\n",
    "        plt.plot(x, y, 'rx')\n",
    "        plt.annotate(nom_features[idx], xy=(x,y))\n",
    "    plt.xlabel(str1 +\" (%s%%)\" % str(pca.explained_variance_ratio_[np1])[:4].lstrip(\"0.\"))\n",
    "    plt.ylabel(str2 +\" (%s%%)\"% str(pca.explained_variance_ratio_[np2])[:4].lstrip(\"0.\"))\n",
    "    plt.xlim((-1,1))\n",
    "    plt.ylim((-1,1))\n",
    "    plt.title(\"Cercle des corrélations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def biplot(pca,np1,np2,data,nom_features):  \n",
    "    cp1 = pca.components_[np1]\n",
    "    cp2 = pca.components_[np2]\n",
    "    xs = pca.transform(data)[:,np1] \n",
    "    ys = pca.transform(data)[:,np2]\n",
    "    for i in range(len(cp1)):\n",
    "        plt.arrow(0, 0, cp1[i]*max(xs), cp2[i]*max(ys),\n",
    "                  color='r', width=0.0005, head_width=0.0025)\n",
    "        plt.text(cp1[i]*max(xs)*1.2, cp2[i]*max(ys)*1.2,\n",
    "                 nom_features[i], color='r')\n",
    "\n",
    "    for i in range(len(xs)):\n",
    "        plt.plot(xs[i], ys[i], 'bo')\n",
    "        plt.text(xs[i]*1.2, ys[i]*1.2, i, color='b')\n",
    "    plt.xlabel(\"CP\" + str(np1) +\" (%s%%)\" % str(pca.explained_variance_ratio_[np1])[:4].lstrip(\"0.\"))\n",
    "    plt.ylabel(\"CP\" + str(np2) +\" (%s%%)\"% str(pca.explained_variance_ratio_[np2])[:4].lstrip(\"0.\"))\n",
    "    plt.title(\"Biplot individus / variables sur les CP\" +str(np1)+\" et \" + str(np2))\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercice 1 : étude de propriétés de vins\n",
    "Le fichier vins.csv contient les résultats d'analyses chimiques de trois classes de vins italiens, provenant de la même région mais de viticulteurs différents. Les analyses portent sur la quantification de 13 indices quantitatifs continus reliés aux vins : degré d'alcool, acide malique, présence de cendres, alcalinité des cendres, magnésium, phénols totaux, flavonoïdes, phénols non flavanoïdes, proanthocyanidines, intensité de la couleur du vin, teinte, OD280/OD315 des vins dilués et proline. Le fichier décrit un vin par ligne (sa classe et ses 13 attributs)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "vins = pd.read_csv(\"./data/vins.csv\",delimiter=\",\",header=None)\n",
    "cat_vins = vins.loc[: , 0]\n",
    "features_vins = vins.loc[:,1:vins.shape[1]]\n",
    "nom_features = ['% alcool', 'acide malique', 'cendres', 'alcalinité', 'magnésium', 'phénols' , \n",
    "                'flavonoïdes', 'non flavanoïdes', 'proanthocyanidines', 'couleur', 'teinte', \n",
    "                'OD280/OD315','proline']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ===== Votre travail : =====\n",
    "\n",
    "### Appliquer une [ACP](https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html) à ces données, de deux manières :\n",
    "\n",
    "- sur les données brutes du tableau\n",
    "- sur les données normalisées, en utilisant la fonction [StandardScaler](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html) de ScikitLearn\n",
    "    \n",
    "### Pour chacune de ces analyses :\n",
    "- déterminer si l'analyse est pertinente et si oui pourquoi\n",
    "- Si elle l'est effectivement, déterminer le nombre de composantes principales à retenir, interpréter les axes principaux, afficher le(s) plan(s) principal(aux) et interpréter graphiquement les résultats\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercice 2 : étude de données image\n",
    "Nous étudions des données image, représentant des chiffres manuscrits. Nous utilisons pour cela la base de données standard MNIST (Mixed National Institute of Standards and Technology), très employée pour le test de nouveaux algorithmes de reconnaissance de ces chiffres. Elle est composée de 60000 images d’apprentissage et 10000 images de test. Les images en noir et blanc, normalisées centrées de 28 pixels de côté."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/sklearn/datasets/_openml.py:932: FutureWarning: The default value of `parser` will change from `'liac-arff'` to `'auto'` in 1.4. You can set `parser='auto'` to silence this warning. Therefore, an `ImportError` will be raised from 1.4 if the dataset is dense and pandas is not installed. Note that the pandas parser may return different data types. See the Notes Section in fetch_openml's API doc for details.\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "import matplotlib\n",
    "Xmnist, ymnist = fetch_openml('mnist_784', version=1, return_X_y=True)\n",
    "\n",
    "def planche(X):\n",
    "    plt.figure(figsize=(9,9))\n",
    "    exemples = (1-np.r_[X[:12000:600], X[13000:30600:600], X[30600:60000:590]]/255)\n",
    "    size = 28\n",
    "    taille = 10\n",
    "    taille = min(len(exemples), taille)\n",
    "    images = [exemple.reshape(size,size) for exemple in exemples]\n",
    "    n_rows = (len(exemples) - 1) // taille + 1\n",
    "    row_images = []\n",
    "    n_empty = n_rows * taille - len(exemples)\n",
    "    images.append(np.zeros((size, size * n_empty)))\n",
    "    for row in range(n_rows):\n",
    "        rimages = images[row * taille : (row + 1) * taille]\n",
    "        row_images.append(np.concatenate(rimages, axis=1))\n",
    "    image = np.concatenate(row_images, axis=0)\n",
    "    plt.imshow(image, cmap = matplotlib.cm.binary)\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n",
    "\n",
    "planche(Xmnist)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'ACP est ici utilisée pour réduire la représentation des données (un point ici est un vecteur de 28*28=784, l'espace original est donc $\\mathbb{R}^{784}$). Intuitivement, on comprend bien que, de nombreux pixels étant noirs et communs à toutes les images, 784 dimensions sont inutiles.\n",
    "\n",
    "Pour ne pas surcharger la visualisation, vous utiliserez un sous-ensemble de ${\\tt nb\\_digits}$ images de MNIST (code donné)\n",
    "## ===== Votre travail consiste à : =====\n",
    "- Calculer une ACP de ces données (normalisées ? non normalisées ? jusitifier)\n",
    "- Projeter les individus dans un  plan principal (ou dans un expace 3D de composantes principales) et commenter le résultat (codes de l'affichage fournis). \n",
    "- Inférer sur le nombre de composantes principales nécessaires pour expliquer les données initiales\n",
    "- Essayer de reconstruire une image donnée à partir de ses coordonnées sur les $n$ premières composantes principales (faire varier $n$) et voir la qualité de la reconstruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utilisation d'un sous-ensemble de Xmnist (pour ne pas surcharger la visualisation)\n",
    "ymnist=ymnist.astype(int)\n",
    "nb_digits = 10000\n",
    "s = np.arange(Xmnist.shape[0])\n",
    "np.random.shuffle(s)\n",
    "X0=Xmnist[s]\n",
    "y0=ymnist[s]\n",
    "Xdata = X0[:nb_digits]\n",
    "ydata = y0[:nb_digits]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction d'affichage sur le plan principal (n1,n2)\n",
    "# x : coordonnées des individus projetés sur les composantes principales\n",
    "# y : label de l'individu (c'est à dire le chiffre lu sur l'image)\n",
    "# n1,n2 : numéro des composantes principales (0 : première CP,  : 2e CP...)\n",
    "def AfficheCP2D (x,y, n1,n2):\n",
    "    fig = plt.figure(figsize=(10, 10))\n",
    "    plt.scatter(x[:, n1], x[:, n2], c=y[:], edgecolor='none', alpha=0.5,cmap=plt.get_cmap('jet', 10), s=5)\n",
    "    plt.xlabel('Composante principale '+str(n1+1))\n",
    "    plt.ylabel('Composante principale '+str(n2+1))\n",
    "    plt.title('MNIST')\n",
    "    plt.colorbar()\n",
    "\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "def AfficheCP3D(x,y, n1,n2,n3):\n",
    "    fig = plt.figure(figsize=(10, 10))\n",
    "    ax = fig.add_subplot(111, projection='3d',elev=30, azim=134)\n",
    "    ax.scatter(x[:, n1], x[:, n2], x[:, n3], c=y, cmap=plt.cm.get_cmap('jet', 30),edgecolor='k')\n",
    "    ax.set_xlabel('Composante principale '+str(n1+1))\n",
    "    ax.set_ylabel('Composante principale '+str(n2+1))\n",
    "    ax.set_zlabel('Composante principale '+str(n3+1))\n",
    "    ax.set_title('MNIST')\n",
    "    ax.w_xaxis.set_ticklabels([])\n",
    "    ax.w_yaxis.set_ticklabels([])\n",
    "    ax.w_zaxis.set_ticklabels([])\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}